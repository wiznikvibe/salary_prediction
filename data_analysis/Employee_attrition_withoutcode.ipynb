{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr2fDvz_oNWV"
      },
      "source": [
        "# <h1><center>**`Employee Attrition Problem`**</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0uBUqHM32IA"
      },
      "source": [
        "### `Dataset Desciption`\n",
        "\n",
        "The dataset folder contains the following files:\n",
        "\n",
        "**train_dataset.csv** = 1000000 x 8\n",
        "\n",
        "**train_salaries.csv** = 1000000 x 2\n",
        "\n",
        "**test_dataset.csv** =  1000000 x 8\n",
        "\n",
        "Columns Provided in the Dataset\n",
        "\n",
        "1. **jobId** - Unique ID that indicates the employee\n",
        "2. **companyId** - Unique ID that idicates the company\n",
        "3. **jobType** - Shows which post the employee is working for the company\n",
        "4. **degree** - shows which degree is completed by the employee\n",
        "5. **major** - shows the field in which the employee is specialised in\n",
        "6. **industry** - show the industry in which the employee is working\n",
        "7. **yearsExperience** - years of working experience the employee is having\n",
        "8. **milesFromMetropolis** - distance in miles between the comapny and his house\n",
        "9. **salary** - salary given to the employee.\n",
        "eg. 250 indicates 2,50,000 in dollars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CsHP6c_HoIzw"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZlT9WjFJoIzy"
      },
      "outputs": [],
      "source": [
        "# Load the train_dataset, train_salaries, test_dataset(pass your file path from drive)\n",
        "\n",
        "data = pd.read_csv(\"C:/users/nikhi/salary_prediction/dataset/train_dataset.csv\")\n",
        "\n",
        "data_salaries = pd.read_csv(\"C:/users/nikhi/salary_prediction/dataset/train_salaries.csv\")\n",
        "\n",
        "test_df = pd.read_csv(\"C:/users/nikhi/salary_prediction/dataset/test_dataset.csv\")\n",
        "test_df = test_df.sample(frac=0.035)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YZZmQydesxmc",
        "outputId": "820b87f1-251f-4c27-e3d1-0d9f9540b83e"
      },
      "outputs": [],
      "source": [
        "# check the train data\n",
        "\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "k5wvgdYos2WO",
        "outputId": "fcee5bde-fe95-4d60-e8e4-f3f60f9f06d9"
      },
      "outputs": [],
      "source": [
        "# check the train data salarie\n",
        "data_salaries.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Xh4014VGs8SJ",
        "outputId": "a280ebe9-f6e4-4b43-c01c-4c0bd3dec845"
      },
      "outputs": [],
      "source": [
        "# check the test data\n",
        "\n",
        "test_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Mc_LVMRqoIzz",
        "outputId": "f056e526-af13-4025-f001-ecc28e3393e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1000000 entries, 0 to 999999\n",
            "Data columns (total 9 columns):\n",
            " #   Column               Non-Null Count    Dtype \n",
            "---  ------               --------------    ----- \n",
            " 0   jobId                1000000 non-null  object\n",
            " 1   companyId            1000000 non-null  object\n",
            " 2   jobType              1000000 non-null  object\n",
            " 3   degree               1000000 non-null  object\n",
            " 4   major                1000000 non-null  object\n",
            " 5   industry             1000000 non-null  object\n",
            " 6   yearsExperience      1000000 non-null  int64 \n",
            " 7   milesFromMetropolis  1000000 non-null  int64 \n",
            " 8   salary               1000000 non-null  int64 \n",
            "dtypes: int64(3), object(6)\n",
            "memory usage: 76.3+ MB\n"
          ]
        }
      ],
      "source": [
        "# Adding salary data to train_dataset using merge on jobId\n",
        "train_data = data.merge(data_salaries,how='left', on='jobId')\n",
        "# train_data.head()\n",
        "train_data.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dEAbw8MIUNJw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jobId</th>\n",
              "      <th>companyId</th>\n",
              "      <th>jobType</th>\n",
              "      <th>degree</th>\n",
              "      <th>major</th>\n",
              "      <th>industry</th>\n",
              "      <th>yearsExperience</th>\n",
              "      <th>milesFromMetropolis</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>915592</th>\n",
              "      <td>JOB1362685323279</td>\n",
              "      <td>COMP58</td>\n",
              "      <td>MANAGER</td>\n",
              "      <td>MASTERS</td>\n",
              "      <td>COMPSCI</td>\n",
              "      <td>OIL</td>\n",
              "      <td>23</td>\n",
              "      <td>50</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508453</th>\n",
              "      <td>JOB1362684916140</td>\n",
              "      <td>COMP49</td>\n",
              "      <td>VICE_PRESIDENT</td>\n",
              "      <td>MASTERS</td>\n",
              "      <td>NONE</td>\n",
              "      <td>AUTO</td>\n",
              "      <td>11</td>\n",
              "      <td>78</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810544</th>\n",
              "      <td>JOB1362685218231</td>\n",
              "      <td>COMP5</td>\n",
              "      <td>JUNIOR</td>\n",
              "      <td>DOCTORAL</td>\n",
              "      <td>PHYSICS</td>\n",
              "      <td>FINANCE</td>\n",
              "      <td>11</td>\n",
              "      <td>90</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6812</th>\n",
              "      <td>JOB1362684414499</td>\n",
              "      <td>COMP14</td>\n",
              "      <td>MANAGER</td>\n",
              "      <td>HIGH_SCHOOL</td>\n",
              "      <td>NONE</td>\n",
              "      <td>FINANCE</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157580</th>\n",
              "      <td>JOB1362684565267</td>\n",
              "      <td>COMP46</td>\n",
              "      <td>VICE_PRESIDENT</td>\n",
              "      <td>BACHELORS</td>\n",
              "      <td>COMPSCI</td>\n",
              "      <td>FINANCE</td>\n",
              "      <td>10</td>\n",
              "      <td>63</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269907</th>\n",
              "      <td>JOB1362684677594</td>\n",
              "      <td>COMP35</td>\n",
              "      <td>SENIOR</td>\n",
              "      <td>HIGH_SCHOOL</td>\n",
              "      <td>NONE</td>\n",
              "      <td>SERVICE</td>\n",
              "      <td>24</td>\n",
              "      <td>79</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704809</th>\n",
              "      <td>JOB1362685112496</td>\n",
              "      <td>COMP3</td>\n",
              "      <td>SENIOR</td>\n",
              "      <td>DOCTORAL</td>\n",
              "      <td>BIOLOGY</td>\n",
              "      <td>FINANCE</td>\n",
              "      <td>13</td>\n",
              "      <td>92</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711452</th>\n",
              "      <td>JOB1362685119139</td>\n",
              "      <td>COMP5</td>\n",
              "      <td>CEO</td>\n",
              "      <td>HIGH_SCHOOL</td>\n",
              "      <td>NONE</td>\n",
              "      <td>EDUCATION</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317503</th>\n",
              "      <td>JOB1362684725190</td>\n",
              "      <td>COMP42</td>\n",
              "      <td>CTO</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>AUTO</td>\n",
              "      <td>11</td>\n",
              "      <td>51</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259031</th>\n",
              "      <td>JOB1362684666718</td>\n",
              "      <td>COMP24</td>\n",
              "      <td>CEO</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>OIL</td>\n",
              "      <td>3</td>\n",
              "      <td>93</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44890 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   jobId companyId         jobType       degree    major  \\\n",
              "915592  JOB1362685323279    COMP58         MANAGER      MASTERS  COMPSCI   \n",
              "508453  JOB1362684916140    COMP49  VICE_PRESIDENT      MASTERS     NONE   \n",
              "810544  JOB1362685218231     COMP5          JUNIOR     DOCTORAL  PHYSICS   \n",
              "6812    JOB1362684414499    COMP14         MANAGER  HIGH_SCHOOL     NONE   \n",
              "157580  JOB1362684565267    COMP46  VICE_PRESIDENT    BACHELORS  COMPSCI   \n",
              "...                  ...       ...             ...          ...      ...   \n",
              "269907  JOB1362684677594    COMP35          SENIOR  HIGH_SCHOOL     NONE   \n",
              "704809  JOB1362685112496     COMP3          SENIOR     DOCTORAL  BIOLOGY   \n",
              "711452  JOB1362685119139     COMP5             CEO  HIGH_SCHOOL     NONE   \n",
              "317503  JOB1362684725190    COMP42             CTO         NONE     NONE   \n",
              "259031  JOB1362684666718    COMP24             CEO         NONE     NONE   \n",
              "\n",
              "         industry  yearsExperience  milesFromMetropolis  salary  \n",
              "915592        OIL               23                   50     148  \n",
              "508453       AUTO               11                   78     101  \n",
              "810544    FINANCE               11                   90      79  \n",
              "6812      FINANCE                5                   23     121  \n",
              "157580    FINANCE               10                   63     138  \n",
              "...           ...              ...                  ...     ...  \n",
              "269907    SERVICE               24                   79      87  \n",
              "704809    FINANCE               13                   92     131  \n",
              "711452  EDUCATION               20                    9     177  \n",
              "317503       AUTO               11                   51     115  \n",
              "259031        OIL                3                   93     118  \n",
              "\n",
              "[44890 rows x 9 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#salaries less that 30 can be removed as such a such salary per month is not expected\n",
        "train_data = train_data[train_data['salary'] > 30]\n",
        "train_data = train_data.sample(frac=0.045)\n",
        "train_data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R77DB8k_oIzz"
      },
      "source": [
        "# Basic EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOU1QjkxoIzz"
      },
      "source": [
        "## Identifying the number of features or columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dLpt1pjoIz0"
      },
      "source": [
        "## Know all the names of the columns¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s77CzsoaoIz0",
        "outputId": "f7fbd176-3c36-491a-e397-7b5f658e5621"
      },
      "outputs": [],
      "source": [
        "# get all column names\n",
        "train_data.columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwqbUBz1oIz2"
      },
      "source": [
        "## Knows more about the data in the columns like data type it contains and total samples of each"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG3UQlHN-kjy",
        "outputId": "d5832e81-cf0a-4e3d-b5ba-33feffb7c00d"
      },
      "outputs": [],
      "source": [
        "# Check which columns are having categorical, numerical or boolean values of train_dataset\n",
        "train_data.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMdW-4ADoIz4",
        "outputId": "8c7a3cef-53f6-4516-df39-8200c77ed637"
      },
      "outputs": [],
      "source": [
        "# Check which columns are having categorical, numerical or boolean values of test_dataset\n",
        "test_df.info()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OJik4SSoIz5"
      },
      "source": [
        "1. After checking the Dtypes of all the columns \n",
        "    1. object - String values\n",
        "    1. int64 - Numerical values\n",
        "1. There are more String values than the numerical values in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjhhJbKIoIz5"
      },
      "source": [
        "## Know more mathematical relations of the dataset like count, min, max values, standarad deviation values, mean and different percentile values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "vvFc2dJFoIz6",
        "outputId": "799af026-d67a-44f0-eebc-12e062f0f4ec"
      },
      "outputs": [],
      "source": [
        "# For train_dataset\n",
        "# For more information on the dataset like the total count in all the columns\n",
        "# min, max values and more information of the respective columns  \n",
        "\n",
        "train_data.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "SKM8G5f8oIz6",
        "outputId": "2305027c-78ed-442c-9354-fd854a568152"
      },
      "outputs": [],
      "source": [
        "# for test_dataset\n",
        "# For more information on the dataset like the total count in all the columns\n",
        "# min, max values and more information of the respective columns\n",
        "test_df.info()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Q_0mG5oIz6"
      },
      "source": [
        "## Get the total number of samples in the dataset using the len() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCHRFn93oIz7",
        "outputId": "403ca32c-279c-43e3-b6f8-d0a0e26d6a2f"
      },
      "outputs": [],
      "source": [
        "# len of train and test dataset\n",
        "print(f\"\"\"Total Length of the Train Data: {len(train_data)}\\n  \n",
        "Total Lenght of Test Data: {len(test_df)}\"\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6ymmsOGoIz7"
      },
      "source": [
        "## Get unique values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SrQayENoIz7",
        "outputId": "04e0a974-6326-4d8e-fc1b-da06dd402cd5"
      },
      "outputs": [],
      "source": [
        "# get how many unique values are in train_dataset\n",
        "\n",
        "train_data.nunique()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpbSbM8ioIz8",
        "outputId": "3e6c5ba9-92cb-4645-fc6a-eece2d758381"
      },
      "outputs": [],
      "source": [
        "# get how many unique values are in test_dataset\n",
        "\n",
        "test_df.nunique()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcELx0b9oIz8"
      },
      "source": [
        "## Counting the total number of missing values¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smt_f1IdoIz8",
        "outputId": "4204af54-5e0c-41b5-e66f-6592e5bd69ed"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in all the columnns of the train_dataset\n",
        "\n",
        "train_data.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nZgoGSwoIz8",
        "outputId": "9ad44834-4dba-4dd4-d0ff-8eec71fd3857"
      },
      "outputs": [],
      "source": [
        " # Check for missing values in all the columnns of the test_dataset\n",
        "test_df.isnull().sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5ARlvYSoIz9"
      },
      "source": [
        "## By the observation gather from the train_data.info(), we can know there are no missing values in the train and test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJae7qRCoIz9"
      },
      "source": [
        "## removing 'jobId' and 'companyId' data from train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "43wF9FahseBR",
        "outputId": "134bd6a4-d10c-4c72-affb-4831f01eb027"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jobType</th>\n",
              "      <th>degree</th>\n",
              "      <th>major</th>\n",
              "      <th>industry</th>\n",
              "      <th>yearsExperience</th>\n",
              "      <th>milesFromMetropolis</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>915592</th>\n",
              "      <td>MANAGER</td>\n",
              "      <td>MASTERS</td>\n",
              "      <td>COMPSCI</td>\n",
              "      <td>OIL</td>\n",
              "      <td>23</td>\n",
              "      <td>50</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508453</th>\n",
              "      <td>VICE_PRESIDENT</td>\n",
              "      <td>MASTERS</td>\n",
              "      <td>NONE</td>\n",
              "      <td>AUTO</td>\n",
              "      <td>11</td>\n",
              "      <td>78</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810544</th>\n",
              "      <td>JUNIOR</td>\n",
              "      <td>DOCTORAL</td>\n",
              "      <td>PHYSICS</td>\n",
              "      <td>FINANCE</td>\n",
              "      <td>11</td>\n",
              "      <td>90</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6812</th>\n",
              "      <td>MANAGER</td>\n",
              "      <td>HIGH_SCHOOL</td>\n",
              "      <td>NONE</td>\n",
              "      <td>FINANCE</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157580</th>\n",
              "      <td>VICE_PRESIDENT</td>\n",
              "      <td>BACHELORS</td>\n",
              "      <td>COMPSCI</td>\n",
              "      <td>FINANCE</td>\n",
              "      <td>10</td>\n",
              "      <td>63</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               jobType       degree    major industry  yearsExperience  \\\n",
              "915592         MANAGER      MASTERS  COMPSCI      OIL               23   \n",
              "508453  VICE_PRESIDENT      MASTERS     NONE     AUTO               11   \n",
              "810544          JUNIOR     DOCTORAL  PHYSICS  FINANCE               11   \n",
              "6812           MANAGER  HIGH_SCHOOL     NONE  FINANCE                5   \n",
              "157580  VICE_PRESIDENT    BACHELORS  COMPSCI  FINANCE               10   \n",
              "\n",
              "        milesFromMetropolis  salary  \n",
              "915592                   50     148  \n",
              "508453                   78     101  \n",
              "810544                   90      79  \n",
              "6812                     23     121  \n",
              "157580                   63     138  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop jobId and companyId from train_dataset\n",
        "train_data = train_data.drop(['jobId','companyId'], axis=1, inplace=False)\n",
        "train_data.head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HFwk9xWyoIz-",
        "outputId": "d200c772-3f48-4bc2-a705-93bc35f8c904"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jobType</th>\n",
              "      <th>degree</th>\n",
              "      <th>major</th>\n",
              "      <th>industry</th>\n",
              "      <th>yearsExperience</th>\n",
              "      <th>milesFromMetropolis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324964</th>\n",
              "      <td>CTO</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>SERVICE</td>\n",
              "      <td>13</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241500</th>\n",
              "      <td>CFO</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>AUTO</td>\n",
              "      <td>20</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141615</th>\n",
              "      <td>VICE_PRESIDENT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>SERVICE</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845579</th>\n",
              "      <td>SENIOR</td>\n",
              "      <td>BACHELORS</td>\n",
              "      <td>PHYSICS</td>\n",
              "      <td>WEB</td>\n",
              "      <td>12</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17609</th>\n",
              "      <td>SENIOR</td>\n",
              "      <td>DOCTORAL</td>\n",
              "      <td>BUSINESS</td>\n",
              "      <td>HEALTH</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               jobType     degree     major industry  yearsExperience  \\\n",
              "324964             CTO       NONE      NONE  SERVICE               13   \n",
              "241500             CFO       NONE      NONE     AUTO               20   \n",
              "141615  VICE_PRESIDENT       NONE      NONE  SERVICE                3   \n",
              "845579          SENIOR  BACHELORS   PHYSICS      WEB               12   \n",
              "17609           SENIOR   DOCTORAL  BUSINESS   HEALTH                1   \n",
              "\n",
              "        milesFromMetropolis  \n",
              "324964                   97  \n",
              "241500                   74  \n",
              "141615                   97  \n",
              "845579                   94  \n",
              "17609                    16  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop jobId and companyId from test_dataset\n",
        "test_data = test_df.drop(['jobId','companyId'], axis=1, inplace=False)\n",
        "test_data.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxMdiTFSoIz-"
      },
      "source": [
        "## Check for categorical columns in the dataset\n",
        "\n",
        "By observing the train_data.info() cell, we can biforcate the datatype for which the object is the values which indicates those are the categorical columns. This dataset has more categorical columns than numerical values\n",
        "\n",
        "1. jobType\n",
        "2. degree\n",
        "3. major\n",
        "4. industry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DMKSHGdoIz_"
      },
      "outputs": [],
      "source": [
        "category_columns = [column for column in train_data.columns if train_data[column].dtype == \"O\"]\n",
        "numerical_columns = [column for column in train_data.columns if column not in category_columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7HPmp72oIz_"
      },
      "source": [
        "## Correlation Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57vTx8IYoIz_"
      },
      "source": [
        "## Why?\n",
        "#### A correlation matrix is a table showing correlation coefficients between variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_bKSsbzoIz_"
      },
      "source": [
        "### There are three broad reasons for computing a correlation matrix:\n",
        "\n",
        "  1. To summarize a large amount of data where the goal is to see patterns. In our example above, the observable pattern is that all the variables highly correlate with each other.\n",
        "  2. To input into other analyses. For example, people commonly use correlation matrixes as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\n",
        "  3. As a diagnostic when checking other analyses. For example, with linear regression, a high amount of correlations suggests that the linear regression estimates will be unreliable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Tnbta8wooI0A",
        "outputId": "9ed1b1c5-21b9-4583-9a43-f5c6f6725fdf"
      },
      "outputs": [],
      "source": [
        "# Correlation metrix using pandas\n",
        "corr = train_data.corr()\n",
        "\n",
        "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WQTlewG8cFW"
      },
      "source": [
        "## From above correlation matrix:\n",
        "1. yearsExperience and salary are positively correlated.\n",
        "\n",
        "2. yearsExperience and milesFromMetropolis have no correlation.\n",
        "\n",
        "3. milesFromMetropolis and salary are weakly negatively correlated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "0gTdNCTOoI0A",
        "outputId": "74bbd74e-af2c-45a5-cf72-a07212298e7c"
      },
      "outputs": [],
      "source": [
        "# Correlation metrix using seaborn\n",
        "ax = sns.heatmap(\n",
        "    corr,\n",
        "    center=0,\n",
        "    cmap='coolwarm',\n",
        "    square=True\n",
        ")\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MQIVQZroI0A"
      },
      "source": [
        "## Chi-square Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5_gu5Mgcnxy"
      },
      "source": [
        "\n",
        "\n",
        "1. The Chi Square statistic is commonly used for testing relationships between categorical variables.\n",
        "\n",
        "2. The null hypothesis of the Chi-Square test is that no relationship exists on the categorical variables in the population; they are independent.\n",
        "\n",
        "3. Example: Is there any significant relationship between gender and education qualification?\n",
        "\n",
        "4. The Chi-Square statistic is most commonly used to evaluate Tests of Independence when using a crosstabulation.\n",
        "\n",
        "5. Crosstabulation presents the distributions of two categorical variables simultaneously, with the intersections of the categories of the variables appearing in the cells of the table. that is values of one variable represents the row and other's value represents the column.\n",
        "\n",
        "6. Formula: x^2 = Summation of( (observed value - Expected value)^2/Expected value )\n",
        "\n",
        "7. The Chi-Square statistic is based on the difference between what is actually observed in the data and what would be expected if there was truly no relationship between the variables.\n",
        "\n",
        "8. This statistic can be evaluated by comparing the actual value against a critical value found in a Chi-Square distribution (where degrees of freedom is calculated as of rows – 1 x columns – 1), but it is easier to simply examine the p-value.\n",
        "\n",
        "9. To make a conclusion about the hypothesis with 95% confidence. Significance(p value of the Chi-square statistic) should be less than 0.05.\n",
        "\n",
        "    1. Alpha level = 0.05(i.e 5%) 95% confidence about conclusion and 5% risk of not making a correct conclusion.\n",
        "\n",
        "    2. Interpret the key results for Chi-Square Test for Association\n",
        "\n",
        "        Determine whether the association between the variables is statistically significant.\n",
        "\n",
        "        Examine the differences between expected counts and observed counts to determine which variable levels may have the most impact on association.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btHTJGSQoI0A"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries for chi-square test\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import chi2\n",
        "\n",
        "def perform_chi_square_test(var_1,var_2):\n",
        "    \n",
        "    #Contingency Table\n",
        "    contingency_table = pd.crosstab(train_data[var_1], train_data[var_2])\n",
        "    \n",
        "    #Observed Values\n",
        "    observed_values = contingency_table.values\n",
        "    \n",
        "    #Expected Values\n",
        "    chi_square_statistic, p_value, degree_f, expected_values= chi2_contingency(contingency_table)\n",
        "\n",
        "    print(\"Degree of Freedom: \",degree_f)\n",
        "    #Significance Level 5%\n",
        "    alpha = 0.05\n",
        "    critical_value = chi2.ppf(q=1-alpha,df=degree_f)\n",
        "    print('Significance level: ',alpha)\n",
        "    print(\"chi-square statistic: \",chi_square_statistic)\n",
        "    print('critical_value:',critical_value)\n",
        "    print('p-value:',p_value)\n",
        "          \n",
        "    if chi_square_statistic>=critical_value:\n",
        "        print(\"Reject H0,There is a relationship between 2 categorical variables\")\n",
        "    else:\n",
        "        print(\"Retain H0,There is no relationship between 2 categorical variables\")\n",
        "\n",
        "    if p_value<=alpha:\n",
        "        print(\"Reject H0,There is a relationship between 2 categorical variables\")\n",
        "    else:\n",
        "        print(\"Retain H0,There is no relationship between 2 categorical variables\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z6tR1WYoI0B",
        "outputId": "a00453d6-f4f7-4101-b0be-3edbd474d9f5"
      },
      "outputs": [],
      "source": [
        "# looping on categorical data list and use function for performing chi-square test on columns from dataset\n",
        "chi_square_test_report = dict()\n",
        "for x in category_columns:\n",
        "    for i in category_columns:\n",
        "        if i != x:\n",
        "            perform_chi_square_test(x,i)\n",
        "            print('-------------------------------------------------------------------\\n')\n",
        "            \n",
        "\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZHW1X6c-xDj"
      },
      "source": [
        "From above chi-square test:\n",
        "\n",
        "- correlated variables:\n",
        "\n",
        "  1. jobtype and degree\n",
        "  2. jobtype and major\n",
        "  3. degree and major\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp3pBTCaoI0B"
      },
      "source": [
        "## Scatter Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j52bv3iQc1Sv"
      },
      "source": [
        "\n",
        "\n",
        "1. A scatter plot is a type of plot using Cartesian coordinates to display values for typically two variables for a set of data.\n",
        "\n",
        "2. The data are displayed as a collection of points, each having the value of one variable determining the position on the horizontal axis and the value of the other variable determining the position on the vertical axis.\n",
        "\n",
        "3. Scatter plot's are used to observe and show relationships between two numeric variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lul6znDSoI0B",
        "outputId": "f1addb69-0d32-4fc7-864a-face25ec3e8b"
      },
      "outputs": [],
      "source": [
        "# Scatter plot using matplotlib \n",
        "# create function for ploting scatterplot between two columns of dataset\n",
        "def plot_scatter(x, y):\n",
        "    plt.figure()\n",
        "    plt.xlabel(x)\n",
        "    plt.ylabel(y)\n",
        "    plt.scatter(train_data[x],train_data[y])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "# Loop through the different columns \n",
        "for i in numerical_columns:\n",
        "    for j in numerical_columns:\n",
        "        if i != j:\n",
        "            plot_scatter(i, j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLU-MyIx_4X5"
      },
      "source": [
        "From above scatter plot\n",
        "\n",
        "1. Increase in value on yearsExperience axis results in increase of values on salary axis. That is they are positively correlated.\n",
        "\n",
        "2. Increase in value on \n",
        "milesFromMetropolis axis results in decrease of values on salary axis. That is they are negatively correlated.\n",
        "\n",
        "2. There is no change in values of yearExperience vs milesFromMetropolis graph. That is there is no correlation between these variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPBbMnO6oI0B"
      },
      "source": [
        "## Histogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY624O-yoI0C"
      },
      "source": [
        "\n",
        "\n",
        "1. A histogram is an approximate representation of the distribution of numerical data.\n",
        "\n",
        "2. To construct a histogram, the first step is to \"bin\" (or \"bucket\") the range of values—that is, divide the entire range of values into a series of intervals—and then count how many values fall into each interval.\n",
        "\n",
        "3. The words used to describe the patterns in a histogram are: \"symmetric\", \"skewed left\" or \"right\", \"unimodal\", \"bimodal\" or \"multimodal\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "mTzS4Po-oI0C",
        "outputId": "d12325c1-5c1a-4ea7-d819-fb8c3a278c4c"
      },
      "outputs": [],
      "source": [
        "# Histogram using pandas \n",
        "train_data.hist(figsize=(12,8))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9GyveWbCRKz"
      },
      "source": [
        "From the above histogram\n",
        "\n",
        "1. yearsExperience data distribution is symmetric.\n",
        "\n",
        "2. milesFromMetropolis data distribution is symmetric.\n",
        "\n",
        "3. salary data distribution is symmetric, unimodel (it has only one peak in distribution)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNMgZ-bpoI0C"
      },
      "source": [
        "## Box Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBBrK3hWoI0D"
      },
      "source": [
        "A boxplot is a standardized way of displaying the dataset based on a five-number summary:\n",
        "\n",
        "    1. Minimum (Q0 or 0th percentile): the lowest data point excluding any outliers.\n",
        "\n",
        "    2. Maximum (Q4 or 100th percentile): the largest data point excluding any outliers.\n",
        "\n",
        "    3. Median (Q2 or 50th percentile): the middle value of the dataset.\n",
        "\n",
        "    4. First quartile (Q1 or 25th percentile): also known as the lower quartile qn(0.25), is the median of the lower half of the dataset.\n",
        "\n",
        "    5. Third quartile (Q3 or 75th percentile): also known as the upper quartile qn(0.75), is the median of the upper half of the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "ZEGifbDioI0D",
        "outputId": "61c0cad3-9816-46cf-93f4-ee2bf6e95879"
      },
      "outputs": [],
      "source": [
        "# box plot using pandas \n",
        "# box plot for yearsExperience column\n",
        "sns.boxplot(train_data['yearsExperience'])\n",
        "print(train_data['yearsExperience'].describe())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRf3_KaVMhng"
      },
      "source": [
        "from above box plot graph:\n",
        "\n",
        "- yearsExperience\n",
        "  1. 25% of employees from dataset has yearExperience of between range 0 to 6.\n",
        "  2. 25% of employee has yearExperience between range 6 to 12.\n",
        "  3. 25% of employee has yearExperience between range 12 to 18.\n",
        "  4. 25% of employee has yearExperience between range 18 to 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "dyEXilQHP9Jw",
        "outputId": "8f3c08e0-33c2-4292-d404-67a025d3e046"
      },
      "outputs": [],
      "source": [
        "# box plot using pandas \n",
        "# box plot for milesFromMetropolies column\n",
        "\n",
        "sns.boxplot(train_data['milesFromMetropolis'])\n",
        "print(train_data['milesFromMetropolis'].describe())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqtFUP0hP8Fj"
      },
      "source": [
        "from above box plot graph:\n",
        "\n",
        "- yearsExperience\n",
        "  1. 25% of employees from dataset has value of milesFromMetropolis between range 0 to 24.\n",
        "  2. 25% of employee has value of milesFromMetropolis between range 24 to 52.\n",
        "  3. 25% of employee has value of milesFromMetropolis between range 52 to 76.\n",
        "  4. 25% of employee has value of milesFromMetropolis between range 76 to 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "AWG2gpBVRN-r",
        "outputId": "670d6469-7d0b-454d-ccce-491127a3df5d"
      },
      "outputs": [],
      "source": [
        "# box plot using pandas \n",
        "# box plot for salary column\n",
        "sns.boxplot(train_data['salary'])\n",
        "print(train_data['salary'].describe())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asX7y3CWRLFz"
      },
      "source": [
        "from above box plot graph:\n",
        "\n",
        "- yearsExperience\n",
        "  1. 25% of employees from dataset has value of salary between range 0 to 88.\n",
        "  2. 25% of employee has value of salary between range 88 to 120.\n",
        "  3. 25% of employee has value of salary between range 120 to 150.\n",
        "  4. 25% of employee has value of salary between range 150 to 300\n",
        "\n",
        "\n",
        "- The mean salary is around 120"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDxrwUAsoI0E"
      },
      "source": [
        "\n",
        "## Violin Plot\n",
        "\n",
        "\n",
        "\n",
        "1. A violin plot is a method of plotting numeric data.\n",
        "\n",
        "1. Violin plots are similar to box plots, except that they also show the probability density of the data at different values, usually smoothed by a kernel density estimator.\n",
        "\n",
        "3. It has:\n",
        "\n",
        "    1. Median (a white dot on the violin plot)\n",
        "    2. Interquartile range (the black bar in the center of violin)\n",
        "    3. The lower/upper adjacent values (the black lines stretched from the bar) — defined as first quartile — 1.5 IQR and third quartile + 1.5 IQR respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "_4ZCqO9boI0E",
        "outputId": "ca78b019-9127-46b2-cb24-23f5bc6171e8"
      },
      "outputs": [],
      "source": [
        "# violin plot for yearsExperience and salary columns\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.violinplot(x=train_data['yearsExperience'],y=train_data['salary'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKq9wocLUnZd"
      },
      "source": [
        "from above violin plot:\n",
        "1. The distribution between lower adjacent value and upper adjacent value is symmetrical.\n",
        "2. also there is higher observation probability at the between first quartile and third quartile. whereas median has the highest.\n",
        "3. The salary range is increasing as we move right on the axis of yearExperience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "vi-O0JGQoI0F",
        "outputId": "161c7f89-dd0d-4066-c184-18444d18889d"
      },
      "outputs": [],
      "source": [
        "# violin plot for milesFromMetropolis from salary columns\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.violinplot(x=train_data['milesFromMetropolis'],y=train_data['salary'])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7MKewIqVeHW"
      },
      "source": [
        "from above violin plot:\n",
        "1. The distribution between lower adjacent value and upper adjacent value is symmetrical.\n",
        "2. also there is higher observation probability at the between first quartile and third quartile.\n",
        "3. The salary range is decreasing as we move right on the axis of milesFromMetropolis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke04B0dsoI0F"
      },
      "source": [
        "\n",
        "## Boxenplot\n",
        "\n",
        "1. The boxen plot, otherwise known as a Letter-value plot, is a box plot meant for large data sets (n > 10,000).\n",
        "\n",
        "2. The Boxen plot is very similar to box plot, except for the fact that it plots different quartile values.\n",
        "\n",
        "3. By plotting different quartile values, we are able to understand the shape of the distribution particularly in the head end and tail end.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "6KfQFQM0oI0F",
        "outputId": "7e877f5c-d5a7-4c16-c8b3-73ba709d6591"
      },
      "outputs": [],
      "source": [
        "# boxen plot for yearsExperience and salary columns\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.boxenplot(x=train_data['yearsExperience'],y=train_data['salary'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEL-XTP-oI0H"
      },
      "source": [
        "## Count Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIIYI9w9djPn"
      },
      "source": [
        "1. A countplot is kind of like a histogram or a bar graph for some categorical area.\n",
        "\n",
        "2. It simply shows the number of occurrences of an item based on a certain type of category.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "fcUoQQhDoI0H",
        "outputId": "87a70a01-b1e3-437b-c1a5-42005264a22f"
      },
      "outputs": [],
      "source": [
        "# count plot of whole datset based on yearsExperience\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.countplot(x='yearsExperience',data=train_data,palette='viridis')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nMJLuxdXyQ_"
      },
      "source": [
        "From above count plot\n",
        "\n",
        "distribution of values of yearExperience is equal over complete dataset, symmetrical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "-SK50aQcoI0I",
        "outputId": "a8d90409-73f4-4a23-8415-7c4f5a08bd58"
      },
      "outputs": [],
      "source": [
        "# count plot of whole datset based on milesFromMetropolis\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.countplot(x='milesFromMetropolis',data=train_data,palette='viridis')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,6))\n",
        "sns.countplot(x='major',data=train_data,palette='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,6))\n",
        "sns.countplot(x='jobType',data=train_data,palette='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,6))\n",
        "sns.countplot(x='degree',data=train_data,palette='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,6))\n",
        "sns.countplot(x='industry',data=train_data,palette='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnE5LN4KX-lU"
      },
      "source": [
        "From above count plot\n",
        "\n",
        "distribution of values of milesFromMetropolis is almost equal over complete dataset, symmetrical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXkVodrHeQ8C"
      },
      "source": [
        "## Subset of train dataset\n",
        "\n",
        "ploting process of swarm plot was taking huge time because of large dataset.\n",
        "\n",
        "So, we take a subset of 50000 samples from train datset and plot it for interpretation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0NcxNeZoI0J"
      },
      "source": [
        "## Swarm Plot\n",
        "\n",
        "\n",
        "\n",
        "1. The swarm plot is a type of scatter plot, but helps in visualizing different categorical variables.\n",
        "\n",
        "2. Scatter plots generally plots based on numeric values, but most of the data analyses happens on categorical variables. So, swarm plots seem very useful in those cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuzzhHMIY72Q"
      },
      "source": [
        "plot data on 50000 of 1000000 sample for clear visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "rzP5ge0LoI0K",
        "outputId": "28d28788-4905-48ae-87cc-45f6c4846694"
      },
      "outputs": [],
      "source": [
        "# swarm plot for yearsExperience and salary columns\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.swarmplot(x=train_data['yearsExperience'],y=train_data['salary'],data=train_data.iloc[:25000], palette='coolwarm')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i59fpDjualk4"
      },
      "source": [
        "from above swarm plot:\n",
        "\n",
        "1. The distribution between lower adjacent value and upper adjacent value is symmetrical.\n",
        "\n",
        "2. also there is higher observation probability at the between first quartile and third quartile.\n",
        "\n",
        "3. The salary range is increasing as we move right on the axis of yearExperience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "JBQ-emTqoI0K",
        "outputId": "cd9a404d-a0e6-4d7d-a009-1bdaef58ca09"
      },
      "outputs": [],
      "source": [
        "# swarm plot for milesFromMetropolis and salary columns\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.swarmplot(x=train_data['milesFromMetropolis'],y=train_data['salary'],data=train_data.iloc[:25000], palette='coolwarm')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wae6ZmbObnWR"
      },
      "source": [
        "from above swarm plot:\n",
        "\n",
        "1. The distribution between lower adjacent value and upper adjacent value is symmetrical.\n",
        "2. also there is higher observation probability at the between first quartile and third quartile.\n",
        "\n",
        "3. The salary range is decreasing as we move right on the axis of milesFromMetropolis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3COrW0TzcHxp"
      },
      "source": [
        "## Combine plot\n",
        "\n",
        "Combination of boxenplot and swarm plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "KJ8gxh9IoI0L",
        "outputId": "7a0336af-ce03-49d4-c193-f0fc39526881"
      },
      "outputs": [],
      "source": [
        "# combine boxen and swarm plot for yearsExperience and salary columns\n",
        "plt.figure(figsize=(20,6))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ixKIqKjcP5i"
      },
      "source": [
        "from above combine plot:\n",
        "\n",
        "1. The distribution between lower adjacent value and upper adjacent value is symmetrical.\n",
        "\n",
        "2. also there is higher observation probability at the between first quartile and third quartile.\n",
        "\n",
        "3. The salary range is increasing as we move right on the axis of yearExperience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "sI6QXGcx7whk",
        "outputId": "ae50cea7-4b96-4259-a9c6-1387db7abf0f"
      },
      "outputs": [],
      "source": [
        "# combine boxen and swarm plot for milesFromMetropolis and salary columns\n",
        "plt.figure(figsize=(20,6))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge-wbO5ncBTZ"
      },
      "source": [
        "from above combine plot:\n",
        "\n",
        "1. The distribution between lower adjacent value and upper adjacent value is symmetrical.\n",
        "2. also there is higher observation probability at the between first quartile and third quartile.\n",
        "\n",
        "3. The salary range is decreasing as we move right on the axis of milesFromMetropolis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m23fShSZseBt"
      },
      "source": [
        "# Strip Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bXB2dUOseBt"
      },
      "source": [
        "A strip plot is a graphical data anlysis technique for summarizing a univariate data set. The strip plot consists of:\n",
        "\n",
        "    1. Horizontal axis = the value of the response variable;\n",
        "    2. Verticalal axis = all values are set to 1.\n",
        "\n",
        "That is, a strip plot is simply a plot of the sorted response values along one axis. The strip plot is an alternative to a histogram or a density plot. It is typically used for small data sets (histograms and density plots are typically preferred for larger data sets). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "_asaCda3seBu",
        "outputId": "a8b54420-c0c1-4e9e-fcc9-8d81cc336b08"
      },
      "outputs": [],
      "source": [
        "# strip plot between yearsExperience and salary columns\n",
        "plt.figure(figsize=(20,6))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP8uGJKzt48X"
      },
      "source": [
        "from above strip plot:\n",
        "\n",
        "Distribution of values of Salary increases for increase in values of yearsExperience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "qq3gf2uvseBu",
        "outputId": "30552251-1e1e-431e-f02f-2334be0bff47"
      },
      "outputs": [],
      "source": [
        "# strip plot between milesFromMetropolis and salary columns\n",
        "plt.figure(figsize=(20,6))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwFCudzQuE5T"
      },
      "source": [
        "from above strip plot:\n",
        "\n",
        "Distribution of values of Salary decreases for increase in values of milesFromMetropolis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50HVkfLrV8Jy"
      },
      "source": [
        "## Variance inflation factor (VIF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1l78DhkseBu"
      },
      "source": [
        "1. The variance inflation factor (VIF) quantifies the extent of correlation between one predictor and the other predictors in a model. \n",
        "2. It is used for diagnosing collinearity/multicollinearity. \n",
        "3. Higher values signify that it is difficult to impossible to assess accurately the contribution of predictors to a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JG5MFf-ZOMe"
      },
      "outputs": [],
      "source": [
        "# import statsmodle library for vif \n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = [col for col in numerical_columns if col != 'salary']\n",
        "train_data[num_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2to3wuHV53j",
        "outputId": "3d674c50-79e8-4d4f-9b95-4029f0154028"
      },
      "outputs": [],
      "source": [
        "# creating a dataframe of just numerical values\n",
        "train_for_vif = train_data[num_cols]\n",
        "\n",
        "\n",
        "# target values\n",
        "target = train_data['salary']\n",
        "\n",
        "\n",
        "# numerical values column names\n",
        "names = ['yearsExperience','milesFromMetropolis']\n",
        "train_for_vif.dropna(inplace=True)\n",
        "names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4OlQ0SmYR-I",
        "outputId": "e14cfc5a-0bf4-4dcd-889a-1adbc20f35a5"
      },
      "outputs": [],
      "source": [
        "# Calculating VIF for each feature.\n",
        "for i in range(0, len(names)):\n",
        "  # taking one column as target variable\n",
        "  y = train_for_vif.loc[:, train_for_vif.columns == names[i]]\n",
        "  # taking all other remaining columns as fetaure variable\n",
        "  x = train_for_vif.loc[:, train_for_vif.columns != names[i]]\n",
        "  # firting the OLS model on y and x\n",
        "  model = sm.OLS(y,x)\n",
        "  results = model.fit()\n",
        " \n",
        "  # geting the r^2 value of results.\n",
        "  rsq = results.rsquared\n",
        "  # calculating vif value\n",
        "  vif = round(1/(1-rsq),2)\n",
        "  print(\"R Square value of {} column is {} keeping all other columns as features\".format(names[i],(round(rsq, 2))))\n",
        "  print(\"Variance inflation Factor of {} columns is {} \\n\".format(names[i], vif))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgWYOixhe_RR"
      },
      "source": [
        "Observations:\n",
        "\n",
        "there is colinearity/multicolinearity between \n",
        "variables as the VIF value is almost upto 2.5\n",
        "\n",
        "1. yearsExperience and milesFromMetropolis both have colinearity with all the variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAjLAfTymlI7"
      },
      "source": [
        "## ANOVA Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZwCskrOzPKv"
      },
      "source": [
        "### Normality Assumption Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SxFscN9ziTe"
      },
      "source": [
        "Before we perform the hypothesis test, we check if the assumptions for the one-way ANOVA hypothesis test are fulfilled. The samples are random and independent samples. Now, we check the normality assumption by plotting a normal probability plot (Q-Q plots) for each grouped variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYbKCsVdznzZ"
      },
      "source": [
        "### Homogeneity of variance Assumption Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9eK67Xrzxpf"
      },
      "source": [
        "### Hypothesis Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI34rpBMzw1c"
      },
      "source": [
        "According to five steps process of hypothesis testing:\n",
        "H₀: μ₁= μ₂ = μ₃ = … = μ₆\n",
        "H₁: Not all salary means are equal\n",
        "α = 0.05\n",
        "According to F test statistics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyv7nMcdmk19"
      },
      "outputs": [],
      "source": [
        "# perform anova test between two variables.\n",
        "\n",
        "def perform_anova_test(x,y):\n",
        "  # two variables of interest\n",
        "  train_anova = train_data[[x,y]]\n",
        "  groups = train_anova.groupby(x).count().reset_index()\n",
        "  # groups.plot(kind='bar',x='major',y='salary')\n",
        "  print(groups)\n",
        "\n",
        "\n",
        "  unique_majors = train_anova[x].unique()\n",
        "  for major in unique_majors:\n",
        "      stats.probplot(train_anova[train_anova[x] == major][y], dist=\"norm\", plot=plt)\n",
        "      plt.title(\"Probability Plot - \" +  str(major))\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  # calculate ratio of the largest to the smallest sample standard deviation\n",
        "  ratio = train_anova.groupby(x).std().max() / train_anova.groupby(x).std().min()\n",
        "  print(ratio)\n",
        "\n",
        "\n",
        "  # Create ANOVA backbone table\n",
        "  data = [['Between Groups', '', '', '', '', '', ''], ['Within Groups', '', '', '', '', '', ''], ['Total', '', '', '', '', '', '']] \n",
        "  anova_table = pd.DataFrame(data, columns = ['Source of Variation', 'SS', 'df', 'MS', 'F', 'P-value', 'F crit'])    #ss=sum of squares source, ms=mean sum of squares source\n",
        "  anova_table.set_index('Source of Variation', inplace = True)\n",
        "\n",
        "  # calculate SSTR and update anova table\n",
        "  x_bar = train_anova[y].mean()\n",
        "  SSTR = train_anova.groupby(x).count() * (train_anova.groupby(x).mean() - x_bar)**2\n",
        "  anova_table['SS']['Between Groups'] = SSTR[y].sum()\n",
        "\n",
        "  # calculate SSE and update anova table\n",
        "  SSE = (train_anova.groupby(x).count() - 1) * train_anova.groupby(x).std()**2\n",
        "  anova_table['SS']['Within Groups'] = SSE[y].sum()\n",
        "\n",
        "  # calculate SSTR and update anova table\n",
        "  SSTR = SSTR[y].sum() + SSE[y].sum()\n",
        "  anova_table['SS']['Total'] = SSTR\n",
        "\n",
        "  # update degree of freedom\n",
        "  anova_table['df']['Between Groups'] = train_anova[x].nunique() - 1\n",
        "  anova_table['df']['Within Groups'] = train_anova.shape[0] - train_anova[x].nunique()\n",
        "  anova_table['df']['Total'] = train_anova.shape[0] - 1\n",
        "\n",
        "  # calculate MS\n",
        "  anova_table['MS'] = anova_table['SS'] / anova_table['df']\n",
        "\n",
        "  # calculate F \n",
        "  F = anova_table['MS']['Between Groups'] / anova_table['MS']['Within Groups']\n",
        "  anova_table['F']['Between Groups'] = F\n",
        "\n",
        "  # p-value\n",
        "  anova_table['P-value']['Between Groups'] = 1 - stats.f.cdf(F, anova_table['df']['Between Groups'], anova_table['df']['Within Groups'])\n",
        "\n",
        "  # F critical \n",
        "  alpha = 0.05\n",
        "  # possible types \"right-tailed, left-tailed, two-tailed\"\n",
        "  tail_hypothesis_type = \"two-tailed\"\n",
        "  if tail_hypothesis_type == \"two-tailed\":\n",
        "      alpha /= 2\n",
        "  anova_table['F crit']['Between Groups'] = stats.f.ppf(1-alpha, anova_table['df']['Between Groups'], anova_table['df']['Within Groups'])\n",
        "\n",
        "  # Final ANOVA Table\n",
        "  print(anova_table)\n",
        "\n",
        "\n",
        "  # The p-value approach\n",
        "  print(\"Approach 1: The p-value approach to hypothesis testing in the decision rule\")\n",
        "  conclusion = \"Failed to reject the null hypothesis.\"\n",
        "  if anova_table['P-value']['Between Groups'] <= alpha:\n",
        "      conclusion = \"Null Hypothesis is rejected.\"\n",
        "  print(\"F-score is:\", anova_table['F']['Between Groups'], \" and p value is:\", anova_table['P-value']['Between Groups'])    \n",
        "  print(conclusion)\n",
        "      \n",
        "  # The critical value approach\n",
        "  print(\"\\n--------------------------------------------------------------------------------------\")\n",
        "  print(\"Approach 2: The critical value approach to hypothesis testing in the decision rule\")\n",
        "  conclusion = \"Failed to reject the null hypothesis.\"\n",
        "  if anova_table['F']['Between Groups'] > anova_table['F crit']['Between Groups']:\n",
        "      conclusion = \"Null Hypothesis is rejected.\"\n",
        "  print(\"F-score is:\", anova_table['F']['Between Groups'], \" and critical value is:\", anova_table['F crit']['Between Groups'])\n",
        "  print(conclusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P-cVMQw4u60V",
        "outputId": "084b7f3e-9add-448d-a4f4-2bacbf6a8d6c"
      },
      "outputs": [],
      "source": [
        "# perform anova test on major and salary\n",
        "perform_anova_test('major', 'salary')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5upd-pxYvCp0",
        "outputId": "67e39a0b-9851-43db-b52f-0d86514ddea6"
      },
      "outputs": [],
      "source": [
        "# perform anova test on jobType and salary\n",
        "\n",
        "perform_anova_test('jobType','salary')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pCYzVyPOvE53",
        "outputId": "9595ae18-bf38-41e6-8821-9d8cdd16bf8a"
      },
      "outputs": [],
      "source": [
        "# perform anova test on degree and salary\n",
        "perform_anova_test('degree','salary')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "be7tDn4gvI5D",
        "outputId": "f796ba4f-0be2-4afc-eba4-33837efcfb5f"
      },
      "outputs": [],
      "source": [
        "# perform anova test on industry and salary\n",
        "perform_anova_test('industry','salary')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WiyuykTZy1Gi",
        "outputId": "64af522b-1cec-48d8-ce92-586248db56fb"
      },
      "outputs": [],
      "source": [
        "# perform anova test on jobType and yearsExperience\n",
        "perform_anova_test('jobType','yearsExperience')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TeB9jtyyyyRy",
        "outputId": "6a062929-7342-400f-b5dc-9200a0c88940"
      },
      "outputs": [],
      "source": [
        "# perform anova test on degree and yearsExperience\n",
        "perform_anova_test('degree','yearsExperience')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tWXBUj7NywTw",
        "outputId": "ad1eea55-edfe-49ed-e96b-b220ad9e2bfa"
      },
      "outputs": [],
      "source": [
        "# perform anova test on major and yearsExperience\n",
        "perform_anova_test('major','yearsExperience')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HQHufKC6vLFq",
        "outputId": "ef98a595-c870-458d-a573-30a1ec6eaa89"
      },
      "outputs": [],
      "source": [
        "# perform anova test on industry and yearsExperience\n",
        "perform_anova_test('industry','yearsExperience')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMaT-Ta4seB2"
      },
      "source": [
        "## Dendrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9tOPEdjmg0c"
      },
      "source": [
        "The dendrogram is a visual representation of the compound correlation data. The individual compounds are arranged along the bottom of the dendrogram and referred to as leaf nodes. Compound clusters are formed by joining individual compounds or existing compound clusters with the join point referred to as a node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "9TgLg79uqby9",
        "outputId": "3941e944-1e4d-4d90-d308-42080377ff60",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Plot a Dendrogram on the columns of the dataset (use 50000 sample of 1000000)\n",
        "X = train_data\n",
        "\n",
        "\n",
        "\n",
        "import scipy\n",
        "from scipy.cluster import hierarchy as hc\n",
        "\n",
        "corr = np.round(scipy.stats.spearmanr(X).correlation, 4)\n",
        "corr_condensed = hc.distance.squareform(1-corr)\n",
        "z = hc.linkage(corr_condensed, method='average')\n",
        "fig = plt.figure(figsize=(16,10))\n",
        "dendrogram = hc.dendrogram(z, labels=X.columns, orientation='left',leaf_font_size=16)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcASQZxGseB3"
      },
      "source": [
        "observation from dendrogram\n",
        "\n",
        "Strongly correlated variables:\n",
        "1. major and degree\n",
        "2. salary and yearsExperience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gW9D8dEKOWL"
      },
      "source": [
        "## Since, there are no missing values and all the data are distributed equally. We can start converting the categoricl values to numerical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS9ZRv_5seB3"
      },
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU_PdrWcseB4"
      },
      "source": [
        "### Why scaling is necessary?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-HBxpvPseB4"
      },
      "source": [
        "* Most of the times, your dataset will contain features highly varying in magnitudes, units and range. But since, most of the machine learning algorithms use Euclidean distance between two data points in their computations, this is a problem.\n",
        "* If left alone, these algorithms only take in the magnitude of features neglecting the units. \n",
        "* The results would vary greatly between different units, 5kg and 5000gms. \n",
        "* The features with high magnitudes will weigh in a lot more in the distance calculations than features with low magnitudes. \n",
        "* To suppress this effect, we need to bring all features to the same level of magnitudes. This can be achieved by scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wHvD9sCseB4"
      },
      "outputs": [],
      "source": [
        "# Helper function for scaling all the numerical data using MinMaxScalar\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "def scale_data(df,col):\n",
        "  \n",
        "  \n",
        "  scaler = StandardScaler(with_mean=False)\n",
        "\n",
        "  df[col] = scaler.fit_transform(df[col])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG7KyrtNseB4"
      },
      "outputs": [],
      "source": [
        "# Making a list of the column names to be scaled \n",
        "col_train = ['yearsExperience','milesFromMetropolis']\n",
        "\n",
        "# passing data and name for scaling\n",
        "train_data = scale_data(train_data, col_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDfHAcV0AjWP"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXsNJlgwgW9d"
      },
      "source": [
        "### One-hot-encoding\n",
        "\n",
        "A one-hot encoding can be applied to the categorical representation. This is where the categorical variable is removed and a new binary variable is added for each unique categorical value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6z-oSvxLgiL"
      },
      "outputs": [],
      "source": [
        "# Importing OneHotEncoder for encoding the categorical data\n",
        "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
        "\n",
        "# class for containing all functionality required for OneHotEncoding\n",
        "class OneHotEncoder(SklearnOneHotEncoder):\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super(OneHotEncoder, self).__init__(**kwargs)\n",
        "        self.fit_flag = False\n",
        "        \n",
        "    # helper function to fit data  \n",
        "    def fit(self, X, **kwargs):\n",
        "        out = super().fit(X)\n",
        "        self.fit_flag = True\n",
        "        return out\n",
        "    \n",
        "    # helper function to transform data  \n",
        "    def transform(self, X, **kwargs):\n",
        "        sparse_matrix = super(OneHotEncoder, self).transform(X)\n",
        "        new_columns = self.get_new_columns(X=X)\n",
        "        d_out = pd.DataFrame(sparse_matrix.toarray(), columns=new_columns, index=X.index)\n",
        "        return d_out\n",
        "    \n",
        "    # helper function to fit and transform data \n",
        "    def fit_transform(self, X, **kwargs):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "    \n",
        "    # helper function to get new column names after fitting and tranforming data \n",
        "    def get_new_columns(self, X):\n",
        "        new_columns = []\n",
        "        for i, column in enumerate(X.columns):\n",
        "            j = 0\n",
        "            while j < len(self.categories_[i]):\n",
        "                new_columns.append(f'{column}{self.categories_[i][j]}')\n",
        "                j += 1\n",
        "        return new_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MHcgPihWoI0M",
        "outputId": "338a25f1-94d1-4d82-8234-6ecd2ab3129d"
      },
      "outputs": [],
      "source": [
        "# Features\n",
        "\n",
        "train_X.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1dO18e6oI0M",
        "outputId": "6c5021e0-32c9-4aca-b4ae-fd7f32e02a07"
      },
      "outputs": [],
      "source": [
        "# Target\n",
        "\n",
        "train_Y.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBErCilgoI0N"
      },
      "outputs": [],
      "source": [
        "#importing Sklearn library for spliting train dataset into train and test dataset(size=0.2)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_X,train_Y, test_size=0.3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v0KZ21Xr1D7r"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries for geting metrics of models\n",
        "import math\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import median_absolute_error\n",
        "\n",
        "# Function for calculating RMSE \n",
        "def rmse(x,y): \n",
        "    return np.sqrt(((x-y)**2).mean())\n",
        "    \n",
        "\n",
        "\n",
        "# Function for calculating all the relevant metrics \n",
        "def print_score(m):\n",
        "    res = [\n",
        "        rmse(m.predict(X_train),y_train),\n",
        "        rmse(m.predict(X_test), y_test),\n",
        "        m.score(X_train, y_train),\n",
        "        m.score(X_test, y_test),\n",
        "        median_absolute_error(m.predict(X_train),y_train),\n",
        "        median_absolute_error(m.predict(X_test),y_test),\n",
        "        metrics.median_absolute_error(m.predict(X_train),y_train),\n",
        "        metrics.median_absolute_error(m.predict(X_test),y_test)\n",
        "    ]\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    print(\"RMSE-Train: \" + str(res[0]) + \"\\nRMSE-Test: \" + str(res[1]) + \"\\nScore-Train: \" + str(res[2]) + \"\\nScore-Test: \" + str(res[3]) +\n",
        "         \"\\nMedian_AE-Train: \" + str(res[4]) + \"\\nMedian_AE-Test: \" + str(res[5]) + \"\\nMeanAE-Train: \" + str(res[6]) + \"\\nMeanAE-Test: \" + str(res[7]),'\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1zRbhGeYseB7"
      },
      "outputs": [],
      "source": [
        "# Visualize importance of all the features in the dataset for the prediction\n",
        "\n",
        "def visualize_importance(feature_importances, feat_train_df):\n",
        "    \n",
        "    # creating dataframe for feature name and feature importance\n",
        "    feature_importance_df = pd.DataFrame()\n",
        "\n",
        "    _df = pd.DataFrame()\n",
        "    _df['feature_importance'] = feature_importances\n",
        "    _df['column'] = feat_train_df.columns\n",
        "    feature_importance_df = pd.concat([feature_importance_df,\n",
        "    _df], axis=0, ignore_index=True)\n",
        "    \n",
        "\n",
        "    # grouping all data and sorting in descending order\n",
        "    order = feature_importance_df.groupby('column')\\\n",
        "        .sum()[['feature_importance']]\\\n",
        "        .sort_values('feature_importance', ascending=False).index[:50]\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    # ploting feature importance data using boxenplot\n",
        "    fig, ax = plt.subplots(figsize=(8, max(6, len(order) * .25)))\n",
        "    sns.boxenplot(\n",
        "        data=feature_importance_df,\n",
        "        x='feature_importance',\n",
        "        y='column',\n",
        "        order= order,\n",
        "        ax= ax,\n",
        "        palette='viridis',\n",
        "        orient='h'\n",
        "    )\n",
        "    ax.tick_params(axis='x', rotation=0)\n",
        "    ax.set_title(\"Importance\")\n",
        "    ax.grid()\n",
        "    fig.tight_layout()\n",
        "\n",
        "    return fig, ax\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOYmZ-wolHao"
      },
      "source": [
        "### NOTE:\n",
        "The employee salaries dataset has 1000000 samples.\n",
        "\n",
        "We have used only 50000 samples for training.\n",
        "\n",
        "If you want you can use complete dataset.\n",
        "\n",
        "Using complete dataset will take longer time to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAvyqEsOseB7"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "jXbLqt2PseB7",
        "outputId": "792a9a54-b491-48af-bfd5-aa1bce02592f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 30.392460195473866\n",
            "RMSE-Test: 30.3935808893334\n",
            "Score-Train: 0.3789528149699647\n",
            "Score-Test: 0.3775718893923019\n",
            "Median_AE-Train: 21.2642236772811\n",
            "Median_AE-Test: 21.51470461191883\n",
            "MeanAE-Train: 21.2642236772811\n",
            "MeanAE-Test: 21.51470461191883 \n",
            "\n",
            "CPU times: total: 234 ms\n",
            "Wall time: 217 ms\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a Linear Regression model to the train dataset\n",
        "\n",
        "# Import LinearRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Instantiate the model\n",
        "lModel = LinearRegression() \n",
        "\n",
        "\n",
        "# Fit the model to the data\n",
        "lModel.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(lModel)\n",
        "\n",
        "\n",
        "\n",
        "# visualizing the inportance of features.\n",
        "fig, ax = visualize_importance(lModel.coef_, train_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1eouB_PseB8"
      },
      "source": [
        "### Random Forest Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w39iBNsaseB8"
      },
      "source": [
        "Random forest is a flexible, easy to use machine learning algorithm that produces, even without hyper-parameter tuning, a great result most of the time. It is also one of the most used algorithms, because of its simplicity and diversity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "pVMtnTvnseB8",
        "outputId": "cbbe869d-f064-4e91-f8b0-8882f02a5f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 8.13090834086457\n",
            "RMSE-Test: 20.964657328075987\n",
            "Score-Train: 0.9555500767820697\n",
            "Score-Test: 0.7038573258507643\n",
            "Median_AE-Train: 5.203125\n",
            "Median_AE-Test: 14.134374999999999\n",
            "MeanAE-Train: 5.203125\n",
            "MeanAE-Test: 14.134374999999999 \n",
            "\n",
            "CPU times: total: 6.2 s\n",
            "Wall time: 6.83 s\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a Random Forest Regressor model to the train dataset\n",
        "\n",
        "# Import RandomForrestRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instantiate the model\n",
        "rf= RandomForestRegressor(n_estimators=64)\n",
        "\n",
        "\n",
        "# Fit the model to the data\n",
        "rf.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(rf)\n",
        "\n",
        "\n",
        "# visualizing the inportance of features.\n",
        "fig, ax = visualize_importance(rf.feature_importances_,train_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwEqj2g1seB8"
      },
      "source": [
        "### KNeighbors Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI2XelYZseB8"
      },
      "source": [
        "KNN regression is a non-parametric method that, in an intuitive manner, approximates the association between independent variables and the continuous outcome by averaging the observations in the same neighbourhood. The size of the neighbourhood needs to be set by the analyst or can be chosen using cross-validation to select the size that minimises the mean-squared error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3q3w-GllACn"
      },
      "source": [
        "### Note:\n",
        "For KNN we used only 10000 samples out of 1000000.\n",
        "You can use complete dataset if you want, it will take longer time to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO2abE0iseB8",
        "outputId": "89dc8df2-e0c5-4b77-db90-e7b259c3fd18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 17.969822324342893\n",
            "RMSE-Test: 22.06893733506741\n",
            "Score-Train: 0.7828896884246401\n",
            "Score-Test: 0.6718379920542594\n",
            "Median_AE-Train: 11.799999999999997\n",
            "Median_AE-Test: 14.599999999999994\n",
            "MeanAE-Train: 11.799999999999997\n",
            "MeanAE-Test: 14.599999999999994 \n",
            "\n",
            "CPU times: total: 3.28 s\n",
            "Wall time: 3.67 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a K-Neighbour Regressor model to the train dataset\n",
        "\n",
        "# Import KNeighbourRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Instantiate the model\n",
        "knnr = KNeighborsRegressor()\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "knnr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(knnr)\n",
        "\n",
        "# fig, ax = visualize_importance(knnr.feature_names_in_, X_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaQr1q3CseB8"
      },
      "source": [
        "### Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mydULhqaseB9"
      },
      "source": [
        "Gradient Boosting Algorithm is generally used when we want to decrease the Bias error.\n",
        "it builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage a regression tree is fit on the negative gradient of the given loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "L_tVAcMWseB9",
        "outputId": "5fb9f7dd-05e9-4992-86de-72174e85514c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 19.609005806938615\n",
            "RMSE-Test: 19.585881574125526\n",
            "Score-Train: 0.7414741142686845\n",
            "Score-Test: 0.7415290697705068\n",
            "Median_AE-Train: 13.817529806121989\n",
            "Median_AE-Test: 13.828321174547256\n",
            "MeanAE-Train: 13.817529806121989\n",
            "MeanAE-Test: 13.828321174547256 \n",
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'columns'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[1;32m<timed exec>:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\nikhi\\salary_prediction\\data_analysis\\Employee_attrition_withoutcode.ipynb Cell 157\u001b[0m line \u001b[0;36mvisualize_importance\u001b[1;34m(feature_importances, feat_train_df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y310sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m _df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y310sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m _df[\u001b[39m'\u001b[39m\u001b[39mfeature_importance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feature_importances\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y310sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m _df[\u001b[39m'\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feat_train_df\u001b[39m.\u001b[39;49mcolumns\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y310sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m feature_importance_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([feature_importance_df,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y310sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m _df], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y310sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# grouping all data and sorting in descending order\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a Gradient Boosting Regressor model to the train dataset\n",
        "\n",
        "# Import GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Instantiate the model\n",
        "GBR = GradientBoostingRegressor()\n",
        "GBR.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(GBR)\n",
        "\n",
        "\n",
        "\n",
        "# visualizing the inportance of features.\n",
        "fig, ax = visualize_importance(GBR.feature_importances_, X_train)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw_O643WseB9"
      },
      "source": [
        "### DecisionTree Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTSZqNroseB9"
      },
      "source": [
        "Decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YNsLWSnseB9",
        "outputId": "3f12dc76-f497-4b7b-c629-f53f894e2617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 1.8907420035863274\n",
            "RMSE-Test: 28.634931765587826\n",
            "Score-Train: 0.9975964263783829\n",
            "Score-Test: 0.4475184714943583\n",
            "Median_AE-Train: 0.0\n",
            "Median_AE-Test: 18.0\n",
            "MeanAE-Train: 0.0\n",
            "MeanAE-Test: 18.0 \n",
            "\n",
            "CPU times: total: 141 ms\n",
            "Wall time: 200 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a Decision Tree Regressor model to the train dataset\n",
        "\n",
        "# Import DecisionTreeRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Instantiate the model\n",
        "DTR = DecisionTreeRegressor()\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "DTR.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(DTR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVI3RRdFseB9"
      },
      "source": [
        "### AdaBoost Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kH6amPAseB-"
      },
      "source": [
        "An AdaBoost regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "zyxsPisuseB-",
        "outputId": "ba991545-24a2-42dd-95fe-affa3dcbd937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 24.781193335994256\n",
            "RMSE-Test: 24.751843461305604\n",
            "Score-Train: 0.5871071936914244\n",
            "Score-Test: 0.5871991747014526\n",
            "Median_AE-Train: 18.916073384446875\n",
            "Median_AE-Test: 19.023408285370536\n",
            "MeanAE-Train: 18.916073384446875\n",
            "MeanAE-Test: 19.023408285370536 \n",
            "\n",
            "CPU times: total: 2.02 s\n",
            "Wall time: 2.27 s\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGoCAYAAABL+58oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAneUlEQVR4nO3de5wlZX3v+88XxjjIIISLE0F0FJmYBBFlREUkjSFsE42gQnArKiFbxH2M0VFzEnW7Rz0Gd2B3gvHlQcIR1IDjFSWgglFaELnLXXFwC97wBmQgA4Iw/M4fq1oXTa+xZ/qyup/5vF+venWtp6qe+tXTC/jyVK1eqSokSZJassWwC5AkSZppBhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCQ1LcnNSQ6cB3WMJflvw65D2lwsGnYBktSyJAEy7DqkzY0zOJI2C0mOTHJhkn9MsjbJd5Ps27X/IMnPkryqb/9Tk5yY5EtJ/jPJV5M8rm/7vkkuS3JH93Pfvm1jSd6T5ELgbuCjwHOA9ydZl+T93X4ndOe+M8kVSZ7T18eqJJ9I8pHu/NcnWdG3fdckn0ny8yS3jffZbTsqybeS/EeSc/rrljYXBhxJm5NnANcAOwCnA6uBpwNPBI6gF0CW9O3/cuDdwI7AVcBpAEm2B84G3tf1NQqcnWSHvmNfARwNbAMcCVwAvK6qllTV67p9LgP2Arbv6vlkksV9fbywq3E74ExgPBhtCZwFfA9YBuzS7UeSQ4C3Ai8GdurO+7GNGyZp4TPgSNqc3FRVp1TVeuDjwK7Au6rq3qo6F/glvbAz7uyqOr+q7gXeBjwrya7A84Ebq+qjVXV/VX0MuAH4s75jT62q67vt901WTFX9a1Xd1u3zv4GHA7/bt8vXqurzXb0fBZ7Ste8D7Ay8paruqqp7qupr3bbXAMdW1beq6n7g74G9nMXR5saAI2lz8tO+9V8AVNXEtv4ZnB+Mr1TVOuB2esFiZ3qzJ/2+R28m5SHHDpLkTd2tpDuSrAW2pTdbNO4nfet3A4uTLKIXzL7XBZiJHgec0N2GW9vVnAm1Sc0z4EjSYLuOr3S3rrYHbumWiTMijwV+1Pe6Jmx/0OvueZv/G/hz4LerajvgDqb2QPIPgMd2YWeyba+pqu36lq2q6utT6FdqhgFHkgb70yT7Jfktes/iXFJVPwA+DyxP8rIki5IcDvw+vediBvkp8IS+19sA9wM/BxYleQfwyCnWdSnwY+C9SbZOsjjJs7ttJwJ/l+QPAJJsm+SwKfYrNcOAI0mDnQ78T3q3efam99AxVXUb8ALgTcBtwN8AL6iqWzfQ1wnAod0nm94HnAN8AVhD7/bWPUzhtlZ3/vX0nvd5IvB94IfA4d22M4D/BaxOcidwHfAnU79kqQ2pmjiLKklKcirww6p6+7BrkbTxnMGRJEnNMeBIkqTmeItKkiQ1xxkcSZLUHL9sU7+y44471rJly4ZdxqTuuusutt5662GXMS85NpNzXAZzbAZzbAabr2NzxRVX3FpVO01sN+DoV5YtW8bll18+7DImNTY2xsjIyLDLmJccm8k5LoM5NoM5NoPN17FJMvGvigPeopIkSQ0y4EiSpOYYcCRJUnMMOJIkaU6Mjo4yOjo6J+fyIWNJkjQn1qxZM2fncgZHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwZlmSr29g20iSsyZpvyTJVUm+n+Tn3fpVSZbNarGSJDVi0bALaF1V7bsJxzwDIMmRwIqqet1M1yVJUsucwZllSdal57gk1yW5Nsnhfbs8MskZSb6Z5MQkD/mdJNkiyY1Jdup7/Z0kOyY5tTvugiRrkryg22fL7pyXJbkmyWvm6JIlSRo6A87ceDGwF/AU4EDguCSP7rbtA7wJeDKwW7fvg1TVA8C/Ai/vmg4Erq6qW7vXy4A/BJ4PnJhkMfCXwB1V9XTg6cCrkzx+xq9MkqR5yFtUc2M/4GNVtR74aZKv0gsddwKXVtV3AZJ8rNv3U5P08SHgc8A/AUcBp/Rt+0QXgm5M8l3gScBBwJ5JDu322RbYHbipv9MkRwNHAyxdupSxsbFpX+xsWLdu3bytbdgcm8k5LoM5NoM5NoPNxNisXbsWYE7G2IAzN7KBbfUbXvcaq36Q5KdJngs8g1/P5gzqI8BfVdU5Gyqsqk4CTgJYsWJFjYyMbGj3oRkbG2O+1jZsjs3kHJfBHJvBHJvBZmJsVq9eDTAnY+wtqrlxPnB491zMTsD+wKXdtn2SPL579uZw4Gsb6OdkereqPtHNBo07rHsuZzfgCcC3gXOA1yZ5GECS5Um2ntnLkiRpfnIGZ/YVcAbwLODq7vXfVNVPkjwJuAh4L71ncM7v9h3kTHq3pk6Z0P5t4KvAUuCYqronycn0ns35RpIAPwcOmaFrkiRpXjPgzKIkOwC3V1UBb+mWX6mqMWBs0PFVdSpwal/TU+g9XHzDhF0vrKo3Tjj2AeCt3SJJ0mbFgDNLkuxML7wcP0P9/S3wWh787I0kSZqEAWeWVNUtwPIZ7O+99G5lTWw/cqbOIUlSK3zIWJIkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDVn0bALkCRJm4fly5fP2bkMOJIkaU6sXLlyzs7lLSpJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRpxoyOjjI6OjrsMiS/qkGSNHPWrFkz7BIkwBkcSZLUIAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAmSDJqiQ/SnJV37LdLJ/z87N9DkmSNieLhl3AsCTZsqrWD9j8j1V1/BzUECBV9aezfS5JkjYnC2IGJ8m7k/x13+v3JHl9krckuSzJNUne2bf9s0muSHJ9kqP72tcleVeSS4BnJXlvkm92x28w0CRZmeRD3fqTk1yX5BHdjM9Hk3wlyY1JXt13zEPqS7IsybeSfAD4BrBrkpuT7NhtPyLJpd3M0QeTbNlX+3uSXJ3k4iRLu/alSc7o2q9Osu+G+pEkaXOQqhp2Db9RkmXAZ6rqaUm2AG4E3gr8EfAaIMCZwD9U1flJtq+q25NsBVwG/GFV3ZakgMOr6hNJtgcuAp5UVZVku6pam2QV8Grg593p/6OqDujOOwb8I/A24K+r6sJu/xcBzwS2Bq4EngHsARw6sT7g+8B3gX2r6uLu+m4GVgA7dfu8uKru60LQxVX1ka72F1bVvyX5B+DOqvp/knwcuKiq/qkLMUuAnQf1M8nYHg0cDbB06dK9V69evYm/pdm1bt06lixZMuwy5iXHZnKOy2CzOTYnnngiAMccc8ys9D/bfN8MNl/H5oADDriiqlZMbF8Qt6iq6uYktyV5KrCUXoh4OnBQtw69/7DvDpwPvD7Ji7r2Xbv224D1wKe79juBe4CTk5wNnNV3yofcoqqqB5IcCVwDfLCqLuzb/Lmq+gXwiyTnAfsA+w2o7/vA98bDzQR/BOwNXNa7e8VWwM+6bb/sq/EK4I+79ecCr+xqXA/ckeQVG+jnQarqJOAkgBUrVtTIyMhkuw3d2NgY87W2YXNsJue4DDabYzP+P0kLdex93wy20MZmQQSczsnAkcDvAB+iFwaOraoP9u+UZAQ4EHhWVd2dZAxY3G2+Z/y5m6q6P8k+XT8vBV5HLyxsyO7AOnozJP0mToMVvVmbyepbBtw1oP8AH66qv5tk23316+m29Wz4d7ehfiRJat6CeAancwbwPHozN+d0y1FJlgAk2SXJo4Bt6d1WujvJk+jdOnqI7rhtq+rzwBuAvTZ08iTbAicA+wM7JDm0b/PBSRYn2QEYoXdbbFB9G/Jl4NDx/ZJsn+RxUzjmtd3+WyZ55Cb2I0lSMxbMDE5V/bK7/bO2m4U5N8nvARd1t2HWAUcAXwSOSXIN8G1gsltBANsAn0uymN6Mxxv7tr0xyRF9rw8B3gF8oKrWJPlL4Lwk53fbLwXOBh4LvLuqbgFuGVDfoE9uUVXfTPL27tq2AO4D/i/gexsYmr8GTupqWg+8tqou2oR+JElqxoIJON1/qJ8JHDbeVlUn0JtVmehPJuujqpb0rf+Y3rMyE/dZBaya5PCj+vb5AfDEri6ANVV19MQDNlDfHhP2W9a3/nHg47+h9k8Bn+rWfwocPMn+k/YjSdLmYEHcokry+8B3gC9X1Y3DrkeSJM1vC2IGp6q+CTxh2HVMppvxkSRJ88iCmMGRJEnaGAYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMWDbsASVI7li9fPuwSJMCAI0maQStXrhx2CRLgLSpJktQgA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRN0+joKKOjo8MuQ1Ifv6pBkqZpzZo1wy5B0gTO4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktScoQacJC9M8rfd+qokb96EPkaS3JHkqm7591mocyzJ95Okr+2zSdb9huO2S/LfZ7qeAeda1/3cOcmn5uKckiTNV0MNOFV1ZlW9dwa6uqCq9uqWA/s3JFk0A/0DrAWe3fW5HfDoKRyzHTBpwEmy5QzV9SBVdUtVHTobfUuStFDMWsBJsizJDUlOTnJdktOSHJjkwiQ3JtknyZFJ3j/Jsbsl+WKSK5JckORJXfthXV9XJzl/A+c+Msknk/wbcG6S7bsZl2uSXJxkz26/VUk+nOTcJDcneXGSf0hybXf+h/V1uxp4abf+YuAzE875liSXded4Z9f8XmC3bmbpuG626bwkpwPXJlmc5JTufFcmOaCv/s91NXw7yf/sO8/KbgyuS/KGAeN+Xbf+B0ku7c5/TZLdf8OvTZKkJszU7MYgTwQOA44GLgNeBuwHvBB4K/DZAcedBBxTVTcmeQbwAeC5wDuA/1JVP+pmUcY9J8lV3fongR8BzwL2rKrbk/wzcGVVHZLkucBHgL26/XcDDgB+H7gIeElV/U2SM4Dn99X4ZeBfupmXl3bX9D8AkhwE7A7sAwQ4M8n+wN8Ce1TVXt1+I90+e1TVTUneBFBVT+5C3LlJlnfn2wfYA7gbuCzJ2UABfwE8ozvPJUm+WlVXDhjHY4ATquq0JL8FPGTWKMnR3bWwdOlSxsbGBnQ1XOvWrZu3tQ2bYzO5uRyXtWvXAiyY34PvmcEcm8EW2tjMdsC5qaquBUhyPfDlqqok1wLLJjsgyRJgX+CTfY+8PLz7eSFwapJP8OAZlAuq6gV9fRwJfKmqbu+a9gNeAlBVX0myQ5Jtu21fqKr7upq2BL7YtU+scT3wNeBwYKuqurmvvoO6ZTxoLKEXeL4/ySVeWlU39dX1z11dNyT5HjAecL5UVbd11/OZbt8Czqiqu/ran9N33okuAt6W5DHAZ6rqxok7VNVJ9AIlK1asqJGRkQFdDdfY2BjztbZhc2wmN5fjsnr1aoAF83vwPTOYYzPYQhub2Q449/atP9D3+oENnHsLYO34rEe/qjqmm9F5PnBVkofs0+euvvVMsr36a6yqB5LcV1Xj7ZPVuBo4A1g1oT3AsVX1wQc1Jss2oa6J9fW/3tD+D+2g6vQkl9Abr3OS/Leq+srG9CFJ0kI07z4mXlV3AjclOQwgPU/p1nerqkuq6h3ArcCuU+z2fODlXR8jwK3deTbWBcCxwMcmtJ8DHNXNPpFklySPAv4T2GaKdS0HHgt8u9v2x92zQ1sBh9CbvTofOCTJI5JsDbyoq2lSSZ4AfLeq3gecCey5EdcqSdKCNdszOJvq5cD/m+TtwMPozZxcDRzXPSgbes/EXA384RT6WwWckuQaes+0vGpTiupmd46fpP3cJL8HXNTdtloHHFFV/6d7qPo64AvA2RMO/QBwYnd77H7gyKq6t+vja8BH6T3HdHpVXQ6Q5FTg0u74kzfw/A30bqcdkeQ+4CfAuzbhsiVJWnBmLeBU1c30HpIdf33kgG2ndm2r+rbfBDxvkj5fPMmpxrqlf79Tx/vtXt8OHDxJf6smvF4y2baqGpnkvBP3PwE4YZJ9XjZJvePb7gGOnKxv4GdV9bpJ+hsFRgfV0j+2VXUsvRknSZI2K/PuFpUkSdJ0zddbVJu1iTNQkiRp4ziDI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1Z0p/6C/Js+l9n9PjumNC76uZnjB7pUmSJG2aqf4l4/8PeCNwBbB+9sqRJEmavqkGnDuq6guzWokkSdIMmWrAOS/JccBngHvHG6vqG7NSlSRJ0jRMNeA8o/u5oq+tgOfObDmSJEnTN6WAU1UHzHYhkiRJM2Wqn6LaDnglsKz/mKp6/axUJUmSNA1TvUX1eeBi4FrggdkrR5IkafqmGnAWV9XKWa1EkiRphkw14Hw0yauBs3jwp6hun5WqJGkBWb58+bBLkDTBVAPOL4HjgLfR+/QU3U//krGkzd7KlU5wS/PNVAPOSuCJVXXrbBYjSZI0E6b6ZZvXA3fPZiGSJEkzZaozOOuBq5Kcx4OfwfFj4pIkad6ZasD5bLdIkiTNe1P9S8Yfnu1CJEmSZspU/5LxTfz601O/UlV+ikqSJM07U71F1f8lm4uBw4DtZ74cSZKk6ZvSp6iq6ra+5UdV9U/4TeKSJGmemuotqqf1vdyC3ozONrNSkSRJ0jRN9RbV/+5bvx+4GfjzGa9GkiYYHR0F/GvBkjbOVD9FdcBsFyJJk1mzZs2wS5C0AG0w4CTZ4P8yVdXozJYjSZI0fb9pBsfnbCRJ0oKzwYBTVe+cq0IkSZJmypQ+Jp7kMUnOSPKzJD9N8ukkj5nt4iRJkjbFVL9N/BTgTGBnYBfg37o2SZKkeWeqAWenqjqlqu7vllOBnWaxLkmSpE021YBza5IjkmzZLUcAt81mYZIkSZtqqgHnKHp/2O8nwI+BQ4G/mK2iJEmSpmOqf8n43cCrquo/AJJsDxxPL/hIkiTNK1OdwdlzPNwAVNXtwFNnpyRJkqTpmWrA2SLJb4+/6GZwpjr7I0mSNKc25ss2v57kU0DRex7nPbNWlSRJ0jRM9cs2P5LkcuC5QIAXV9U3Z7UySZKkTTTl20xdoDHUSJKkeW+qz+BIkiQtGAYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeDMsCRf38j9R5KctYnnekOSR2zKsZIktcyAM8Oqat85PN0bgEkDTpIt57AOSZLmFQPODEuyrvs5kmQsyaeS3JDktCTptj2va/sa8OK+Y1cleXPf6+uSLEuydZKzk1zdtR2e5PXAzsB5Sc4bP3eSdyW5BHh7kjP6+vrjJJ+Zm1GQJGm4/MLM2fVU4A+AW4ALgWd3X3nxL/S+9uI7wMen0M/zgFuq6vkASbatqjuSrAQOqKpbu/22Bq6rqnd0YepbSXaqqp8DfwGcMrHjJEcDRwMsXbqUsbGxTb/aWbRu3bp5W9uwtT42a9euBdjoa2x9XKbDsRnMsRlsoY2NAWd2XVpVPwRIchWwDFgH3FRVN3bt/0oXMDbgWuD4JP8LOKuqLhiw33rg0wBVVUk+ChyR5BTgWcArJx5QVScBJwGsWLGiRkZGNub65szY2BjztbZha31sVq9eDbDR19j6uEyHYzOYYzPYQhsbb1HNrnv71tfz60BZA/a/nwf/ThYDVNUaYG96QefYJO8YcPw9VbW+7/UpwBHAfwU+WVX3b1z5kiQtTAacuXcD8Pgku3Wv/2vftpuBpwEkeRrw+G59Z+DuqvpX4PjxfYD/BLYZdKKquoXe7bG3A6fO2BVIkjTPeYtqjlXVPd1zL2cnuRX4GrBHt/nTwCu721mXAWu69icDxyV5ALgPeG3XfhLwhSQ/rqoDBpzyNGCn7tvgJUnaLBhwZlhVLel+jgFjfe2v61v/IvCkSY79BXDQJN3eDJwzyf7/DPzzxHNPsB+9h5olSdpsGHAaluQK4C7gTcOuRZKkuWTAaVhV7T3sGiRJGgYfMpYkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1x4AjSZKas2jYBUjShixfvnzYJUhagAw4kua1lStXDrsESQuQt6gkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJKmZXR0lNHR0WGXIUkP4lc1SJqWNWvWDLsESXoIZ3AkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFnAUuyIsn7hl2HJEnzzaJhF6BNV1WXA5dPdf8ki6rq/lksSZKkecEZnCFLsizJDUlOTnJdktOSHJjkwiQ3JtmnW76e5Mru5+92x44kOatb3z7JZ5Nck+TiJHt27auSnJTkXOAjQ7xUSZLmjDM488MTgcOAo4HLgJcB+wEvBN4KvBLYv6ruT3Ig8PfASyb08U7gyqo6JMlz6YWZvbptewP7VdUvJp44ydHdeVm6dCljY2Mze2UzZN26dfO2tmEb9tisXbsWYN79foY9LvOZYzOYYzPYQhsbA878cFNVXQuQ5Hrgy1VVSa4FlgHbAh9OsjtQwMMm6WM/utBTVV9JskOSbbttZ04Wbrp9TwJOAlixYkWNjIzM3FXNoLGxMeZrbcM27LFZvXo1wLz7/Qx7XOYzx2Ywx2awhTY23qKaH+7tW3+g7/UD9ELou4HzqmoP4M+AxZP0kUnaqvt51wzVKUnSgmDAWRi2BX7UrR85YJ/zgZdD79kc4NaqunO2C5MkaT4y4CwM/wAcm+RCYMsJ28ZnaVYBK5JcA7wXeNXclSdJ0vziMzhDVlU3A3v0vT5ywLblfYf9j+7nDsDt3b63AwdP0v+qGSxXkqQFwYCzQCV5IfAe4Khh1yJJ0nxjwFmgqupM4Mxh1yFJ0nzkMziSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScxYNuwBJC9vy5cuHXYIkPYQBR9K0rFy5ctglSNJDeItKkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwNGsGB0dZXR0dNhlSJI2U34XlWbFmjVrhl2CJGkz5gyOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAGZIkq5K8edh1SJLUIgPOApZky2HXIEnSfGTAmUNJ3pbk20n+Hfjdrm23JF9MckWSC5I8qa/94iSXJXlXknVd+0iS85KcDlybZMskx3X7XZPkNX3ne0tf+zuHcc2SJA3DomEXsLlIsjfwUuCp9Mb9G8AVwEnAMVV1Y5JnAB8AngucAJxQVR9LcsyE7vYB9qiqm5IcDdxRVU9P8nDgwiTnArt3yz5AgDOT7F9V58/+1UqSNFwGnLnzHOCMqrobIMmZwGJgX+CTScb3e3j381nAId366cDxfX1dWlU3desHAXsmObR7vS29YHNQt1zZtS/p2h8UcLqAdDTA0qVLGRsbm841/sratWsBZqy/devWzVhfrXFsJue4DObYDObYDLbQxsaAM7dqwustgLVVtddG9nNX33qAv6qqc/p3SPJfgGOr6oMbLKjqJHqzSKxYsaJGRkY2spTJrV69GoCZ6m9sbGzG+mqNYzM5x2Uwx2Ywx2awhTY2PoMzd84HXpRkqyTbAH8G3A3clOQwgPQ8pdv/YuAl3fpLN9DvOcBrkzys62N5kq279qOSLOnad0nyqBm/KkmS5iEDzhypqm8AHweuAj4NXNBtejnwl0muBq4HDu7a3wCsTHIp8GjgjgFdnwx8E/hGkuuADwKLqupcere2LkpyLfApYJsZvixJkuYlb1HNoap6D/CeSTY9b5K2HwHPrKpK8lLg8q6PMWCsr88HgLd2y8TznUDvYWVJkjYrBpz5a2/g/ek9fbwWOGq45UiStHAYcOapqroAeMpv3FGSJD2Ez+BIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5iwadgFq0/Lly4ddgiRpM2bA0axYuXLlsEuQJG3GvEUlSZKaY8CRJEnNMeBIkqTmGHAkSVJzUlXDrkHzRJKfA98bdh0D7AjcOuwi5inHZnKOy2COzWCOzWDzdWweV1U7TWw04GhBSHJ5Va0Ydh3zkWMzOcdlMMdmMMdmsIU2Nt6ikiRJzTHgSJKk5hhwtFCcNOwC5jHHZnKOy2COzWCOzWALamx8BkeSJDXHGRxJktQcA44kSWqOAUdDleR5Sb6d5DtJ/naS7Unyvm77NUme1rft5iTXJrkqyeVzW/nsm8LYPCnJRUnuTfLmjTl2oZvm2Gzu75uXd/8sXZPk60meMtVjF7Jpjsvm/p45uBuXq5JcnmS/qR47VFXl4jKUBdgS+D/AE4DfAq4Gfn/CPn8KfAEI8Ezgkr5tNwM7Dvs6hjg2jwKeDrwHePPGHLuQl+mMje+bAtgX+O1u/U/G/5lq+X0znXHxPVMAS/j1M7t7AjcshPeMMzgapn2A71TVd6vql8Bq4OAJ+xwMfKR6Lga2S/LouS50CH7j2FTVz6rqMuC+jT12gZvO2LRuKmPz9ar6j+7lxcBjpnrsAjadcWndVMZmXXWJBtgaqKkeO0wGHA3TLsAP+l7/sGub6j4FnJvkiiRHz1qVwzGVsZmNYxeC6V6f75tf+0t6M6SbcuxCMp1xAd8zJHlRkhuAs4GjNubYYVk07AK0WcskbRP/bsGG9nl2Vd2S5FHAl5LcUFXnz2iFwzOVsZmNYxeC6V6f7xsgyQH0/kM+/jxFy++b6YwL+J6hqs4AzkiyP/Bu4MCpHjsszuBomH4I7Nr3+jHALVPdp6rGf/4MOIPedGkrpjI2s3HsQjCt6/N9A0n2BE4GDq6q2zbm2AVqOuPie6ZPF+x2S7Ljxh471ww4GqbLgN2TPD7JbwEvBc6csM+ZwCu7T1M9E7ijqn6cZOsk2wAk2Ro4CLhuLoufZVMZm9k4diHY5OvzfQNJHgt8BnhFVa3ZmGMXsE0eF98zkOSJSdKtP43eA8W3TeXYYfIWlYamqu5P8jrgHHpP43+oqq5Pcky3/UTg8/Q+SfUd4G7gL7rDl9KbLoXe+/j0qvriHF/CrJnK2CT5HeBy4JHAA0neQO8TDHdOduxQLmQWTGdsgB3ZzN83wDuAHYAPdONwf1WtGHTsUC5khk1nXPDfNScCL6H3P5r3Ab8ADu8eOp7X7xm/qkGSJDXHW1SSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EhaEJK8Psm3kpy2kcctS/Ky2aqr7zyfT7LdbJ+n73zbJfnvc3U+aaHx7+BIWhC6L/r7k6q6aSOPGwHeXFUv2Mjjtqyq9RtzzFxJsiW9P5F/VlXtMex6pPnIGRxJ816SE4EnAGcmeVuSDyW5LMmVSQ7u9lmW5IIk3+iWfbvD3ws8J8lVSd6Y5Mgk7+/r+6wuBJFkXZJ3JbkEeFaSI5Jc2h37wS5YDKrx5iQ7dnXckOTkJNclOS3JgUkuTHJjkn26/Vcl+WiSr3Ttr+7ak+S47thrkxzetY8kOS/J6cC13XXt1tV2XJIlSb7cXfu1E8blW0n+Jcn1Sc5NslW37YlJ/j3J1d1xu3Xtb+nG95ok75yp36M0p6rKxcXFZd4vwM30vmrh74EjurbtgDXA1sAjgMVd++7A5d36CL2ZjvF+jgTe3/f6LGCkWy/gz7v13wP+DXhY9/oDwCunUN8y4H7gyfT+J/IK4EP0vnn5YOCz3f6rgKuBrbrjfgDsTO/P4n+J3p++Xwp8H3h0dx13AY/vjl8GXNd3/kXAI7v1Hel9vUn66tmr2/aJvvG7BHhRt764G8ODgJO6Y7foxmf/Yf/+XVw2dvG7qCQtNAcBL0zy5u71YuCx9L7F+P1J9gLWA8s3oe/1wKe79T8C9gYu676HaCvgZ1Ps56aquhYgyfXAl6uqklxLL3CM+1xV/QL4RZLz6H1L9X7Ax6p3e+ynSb4KPB24E7i0Bt+iC/D3SfYHHgB2oReQxuu5qlu/AliW3hdI7lJVZwBU1T1dvQfRG+Mru/2X0AuM50/x2qV5wYAjaaEJ8JKq+vaDGpNVwE+Bp9CbebhnwPH38+Db84v71u+pXz93E+DDVfV3m1DjvX3rD/S9foAH/3t34kOQ1Z13kLs2sO3lwE7A3lV1X5Kb+fW19deznl5YG3SeAMdW1Qc3cC5p3vMZHEkLzTnAX6WbVkny1K59W+DHVfUA8Ap6t3gA/hPYpu/4m4G9kmyRZFd6syaT+TJwaJJHdefZPsnjZvRK4OAki5PsQO8W1GX0ZkoOT7Jlkp2A/YFLJzl24nVtC/ysCzcHABustaruBH6Y5BCAJA9P8gh643tUkiVd+y7jYyAtJAYcSQvNu4GHAdckua57Db1nZF6V5GJ6t6fGZzuuAe7vHqR9I3AhcBO9B3WPB74x2Umq6pvA24Fzk1xD77mYR8/wtVwKnA1cDLy7qm4Bzuhqvhr4CvA3VfWTSeq7Dbiwexj5OOA0YEWSy+nN5twwhfO/Anh9d31fB36nqs4FTgcu6m6pfYoHBylpQfBj4pI0BN0ttXVVdfywa5Fa5AyOJElqjjM4krQRur+R8/AJza8Y/9SUpPnBgCNJkprjLSpJktQcA44kSWqOAUeSJDXHgCNJkprz/wN5wQi78JHtEQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a AdaBoost Regressor model to the train dataset\n",
        "\n",
        "# Import AdaBoostRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "# Instantiate the model\n",
        "AdaBoost = AdaBoostRegressor()\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "AdaBoost.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(AdaBoost)\n",
        "\n",
        "\n",
        "\n",
        "# visualizing the inportance of features.\n",
        "fig, ax = visualize_importance(AdaBoost.feature_importances_, train_X)\n",
        "\n",
        "# visualizing the importance of features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-fxKyi-seB-"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVxAgLgrseB-"
      },
      "source": [
        "XGBoost is an ensemble learning method. Sometimes, it may not be sufficient to rely upon the results of just one machine learning model. Ensemble learning offers a systematic solution to combine the predictive power of multiple learners. The resultant is a single model which gives the aggregated output from several models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "cq6vOx4nseB-",
        "outputId": "8418c714-65ac-44d6-8cb4-0e746f4939c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 16.938098333392734\n",
            "RMSE-Test: 19.53439906412938\n",
            "Score-Train: 0.8071044609756095\n",
            "Score-Test: 0.7428860925299199\n",
            "Median_AE-Train: 11.854217529296875\n",
            "Median_AE-Test: 13.584354400634766\n",
            "MeanAE-Train: 11.854217529296875\n",
            "MeanAE-Test: 13.584354400634766 \n",
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'columns'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[1;32m<timed exec>:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\nikhi\\salary_prediction\\data_analysis\\Employee_attrition_withoutcode.ipynb Cell 167\u001b[0m line \u001b[0;36mvisualize_importance\u001b[1;34m(feature_importances, feat_train_df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y323sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m _df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y323sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m _df[\u001b[39m'\u001b[39m\u001b[39mfeature_importance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feature_importances\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y323sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m _df[\u001b[39m'\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feat_train_df\u001b[39m.\u001b[39;49mcolumns\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y323sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m feature_importance_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([feature_importance_df,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y323sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m _df], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y323sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# grouping all data and sorting in descending order\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a XGB Regressor model to the train dataset\n",
        "import xgboost\n",
        "# Import XGBRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Instantiate the model\n",
        "xgbr =XGBRegressor()\n",
        "\n",
        "\n",
        "# Fit the model to the data\n",
        "xgbr.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(xgbr)\n",
        "\n",
        "\n",
        "# visualizing the inportance of features.\n",
        "fig, ax = visualize_importance(xgbr.feature_importances_, X_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akOKcjNWseB_"
      },
      "source": [
        "### Light Gradient Boosted Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppIsGpcIseB_"
      },
      "source": [
        "Light GBM is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithm, used for ranking, classification and many other machine learning tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "Lebzs08bseB_",
        "outputId": "4a146dce-22de-4b74-cd84-a24a1a8badf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 160\n",
            "[LightGBM] [Info] Number of data points in the train set: 35912, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 116.143100\n",
            "RMSE-Train: 18.47724465244436\n",
            "RMSE-Test: 18.94311351574282\n",
            "Score-Train: 0.7704552824437051\n",
            "Score-Test: 0.7582156532773087\n",
            "Median_AE-Train: 13.071903296526656\n",
            "Median_AE-Test: 13.303288066455828\n",
            "MeanAE-Train: 13.071903296526656\n",
            "MeanAE-Test: 13.303288066455828 \n",
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'columns'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[1;32m<timed exec>:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\nikhi\\salary_prediction\\data_analysis\\Employee_attrition_withoutcode.ipynb Cell 171\u001b[0m line \u001b[0;36mvisualize_importance\u001b[1;34m(feature_importances, feat_train_df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y330sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m _df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y330sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m _df[\u001b[39m'\u001b[39m\u001b[39mfeature_importance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feature_importances\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y330sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m _df[\u001b[39m'\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feat_train_df\u001b[39m.\u001b[39;49mcolumns\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y330sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m feature_importance_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([feature_importance_df,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y330sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m _df], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y330sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# grouping all data and sorting in descending order\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a lightgbm Regressor model to the train dataset\n",
        "\n",
        "# Import lightgbm\n",
        "import lightgbm as lgbm\n",
        "\n",
        "# Instantiate the model\n",
        "lg = lgbm.LGBMRegressor()\n",
        "\n",
        "\n",
        "# Fit the model to the data\n",
        "lg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(lg)\n",
        "\n",
        "\n",
        "# visualizing the inportance of features.\n",
        "fig, ax = visualize_importance(lg.feature_importances_, X_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTu2baDaseB_"
      },
      "source": [
        "### Comparing all the model based on metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8emQZJdEseB_"
      },
      "outputs": [],
      "source": [
        "# the libraries we need\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "def compare_models(models,names,X_train,y_train,X_test,y_test):\n",
        "\n",
        "\n",
        "    # now, create a list with the objects \n",
        "    data = {'Metric':['rmse','MedAE','MAE','R-squared']}\n",
        "    df_train = pd.DataFrame(data)\n",
        "    df_test = pd.DataFrame(data)\n",
        "\n",
        "    def rmse(x,y):\n",
        "      return math.sqrt(((x-y)**2).mean())\n",
        "\n",
        "\n",
        "    for (model,name) in zip(models,names):\n",
        "      y_pred= model.predict(X_test) # then predict on the test set\n",
        "      res = [rmse(model.predict(X_train), y_train),rmse(model.predict(X_test), y_test),\n",
        "                metrics.median_absolute_error(model.predict(X_train), y_train),metrics.median_absolute_error(model.predict(X_test), y_test),\n",
        "                metrics.mean_absolute_error(model.predict(X_train), y_train),metrics.mean_absolute_error(model.predict(X_test), y_test),\n",
        "                metrics.r2_score(model.predict(X_train), y_train),metrics.r2_score(model.predict(X_test), y_test)]\n",
        "      df_train[name] = [res[0], res[2], res[4], res[6]]\n",
        "      df_test[name] = [res[1], res[3], res[5], res[7]]\n",
        "    return df_train,df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "enc2RVZuseB_"
      },
      "outputs": [],
      "source": [
        "# list of models object\n",
        "# list of models name\n",
        "models= [lg, DTR, rf, knnr, GBR, xgbr, AdaBoost]\n",
        "names = ['Lr', 'Dtree', 'Forest', 'Knn','GBR', 'Xboost', 'AdaBoost']\n",
        "comp_model_train,comp_model_test = compare_models(models,names,X_train,y_train,X_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj2HpWIYseB_"
      },
      "source": [
        "#### RMSE of all model on train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUxTv0_EseCA",
        "outputId": "57f32628-d04b-4f12-fb5a-9c69f99a9ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Metric         Lr     Dtree    Forest        Knn        GBR     Xboost  \\\n",
            "0   rmse  18.477245  1.890742  8.130908  17.969822  19.609006  16.938098   \n",
            "\n",
            "    AdaBoost  \n",
            "0  24.781193  \n"
          ]
        }
      ],
      "source": [
        "# printing rmse comparision of model on train and test\n",
        "\n",
        "print(comp_model_train[:1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_R9Ka_AseCA"
      },
      "source": [
        "#### All metrics on train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "oMLRhYhMseCB",
        "outputId": "ab605958-c721-4711-d697-1ef5056528d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Lr</th>\n",
              "      <th>Dtree</th>\n",
              "      <th>Forest</th>\n",
              "      <th>Knn</th>\n",
              "      <th>GBR</th>\n",
              "      <th>Xboost</th>\n",
              "      <th>AdaBoost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rmse</td>\n",
              "      <td>18.477245</td>\n",
              "      <td>1.890742</td>\n",
              "      <td>8.130908</td>\n",
              "      <td>17.969822</td>\n",
              "      <td>19.609006</td>\n",
              "      <td>16.938098</td>\n",
              "      <td>24.781193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MedAE</td>\n",
              "      <td>13.071903</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.203125</td>\n",
              "      <td>11.800000</td>\n",
              "      <td>13.817530</td>\n",
              "      <td>11.854218</td>\n",
              "      <td>18.916073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MAE</td>\n",
              "      <td>14.998634</td>\n",
              "      <td>0.269845</td>\n",
              "      <td>6.362421</td>\n",
              "      <td>14.158872</td>\n",
              "      <td>15.810184</td>\n",
              "      <td>13.688657</td>\n",
              "      <td>20.646531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>R-squared</td>\n",
              "      <td>0.691039</td>\n",
              "      <td>0.997591</td>\n",
              "      <td>0.947161</td>\n",
              "      <td>0.713767</td>\n",
              "      <td>0.599917</td>\n",
              "      <td>0.752154</td>\n",
              "      <td>0.220684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Metric         Lr     Dtree    Forest        Knn        GBR     Xboost  \\\n",
              "0       rmse  18.477245  1.890742  8.130908  17.969822  19.609006  16.938098   \n",
              "1      MedAE  13.071903  0.000000  5.203125  11.800000  13.817530  11.854218   \n",
              "2        MAE  14.998634  0.269845  6.362421  14.158872  15.810184  13.688657   \n",
              "3  R-squared   0.691039  0.997591  0.947161   0.713767   0.599917   0.752154   \n",
              "\n",
              "    AdaBoost  \n",
              "0  24.781193  \n",
              "1  18.916073  \n",
              "2  20.646531  \n",
              "3   0.220684  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# printing comparision of model on train and test\n",
        "\n",
        "comp_model_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_xNw3OwoI0O"
      },
      "source": [
        "## Hyperparameter Tunning\n",
        "\n",
        "A hyperparameter is a parameter whose value is set before the learning process begins.\n",
        "\n",
        "Hyperparameters tuning is crucial as they control the overall behavior of a machine learning model. \n",
        "\n",
        "Every machine learning models will have different hyperparameters that can be set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNXfkYR6seCB"
      },
      "source": [
        "### RamdomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hLpl6xduL3p"
      },
      "source": [
        "RandomizedSearchCV is very useful when we have many parameters to try and the training time is very long.\n",
        " 1. The first step is to write the parameters that we want to consider\n",
        " 2. From these parameters select the best ones.(which are printed in output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5TLQOn_uoI0O"
      },
      "outputs": [],
      "source": [
        "# Helper function to perform hyper parameter tunning with RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "def random_Search(model,X_train, Y_train,param_grid):\n",
        "  \n",
        "\n",
        "  # Random search of parameters, using 3 fold cross validation, \n",
        "  # search across 100 different combinations, and use all available cores\n",
        "  random = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=20, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "  random.fit(X_train, Y_train)\n",
        "  print(random.best_params_)\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhss8qN1oI0P",
        "outputId": "b6fa8f69-c805-49de-b9ec-6beb1b1bf3d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "{'n_estimators': 64, 'min_samples_leaf': 0.1, 'max_features': 'auto', 'max_depth': 27.0, 'bootstrap': False}\n"
          ]
        }
      ],
      "source": [
        "# create parameters dict for tunning\n",
        "rf_para_grid = {'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 200],\n",
        "               'max_features': ['auto', 'sqrt'],\n",
        "               'max_depth': np.linspace(1, 32, 32, endpoint=True),\n",
        "               'min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True),\n",
        "               'bootstrap': [True, False]}\n",
        "\n",
        "# passing data for hyper parameter tunning with Randomized search cv\n",
        "random_Search(RandomForestRegressor(), X_train, y_train, param_grid=rf_para_grid)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIabALwiseCC",
        "outputId": "6e5c897d-3e9f-4e8e-cd54-9762d7c86056"
      },
      "outputs": [],
      "source": [
        "# Import GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# create GradientBoostRegressor parameters dict for tunning\n",
        "GBR_para_grid = {\n",
        "'n_estimators':  [1, 2, 4, 8, 16, 32, 64, 100, 200], \n",
        " 'learning_rate' : [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
        " 'max_depth': np.linspace(1, 32, 32, endpoint=True), \n",
        " 'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True)\n",
        "}\n",
        "\n",
        "# passing data for hyper parameter tunning with Randomized search cv\n",
        "random_Search(GradientBoostingRegressor(), X_train, y_train, GBR_para_grid)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytccyieVseCD",
        "outputId": "14407a04-488e-43a7-bf7d-6073bd7001e2"
      },
      "outputs": [],
      "source": [
        "# create DecisionTreeRegressor parameters dict for tunning\n",
        "DTR_para_grid = {\n",
        "                  \"splitter\":[\"best\",\"random\"],\n",
        "            \"max_depth\" : np.linspace(1, 32, 32, endpoint=True),\n",
        "           \"min_samples_leaf\":np.linspace(0.1, 0.5, 5, endpoint=True),\n",
        "           \"min_weight_fraction_leaf\":[0.1,0.2,0.5,0.9],\n",
        "           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
        "           }\n",
        "\n",
        "# passing data for hyper parameter tunning with Randomized search cv\n",
        "random_Search(DecisionTreeRegressor(), X_train, y_train, DTR_para_grid)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AItmwuYPseCD",
        "outputId": "5b2de119-0db7-4c8e-da98-3dabc8f17945"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "# create parameters dict for tunning\n",
        "XGB_para_grid = {\n",
        "    \"learning_rate\"    : [0.05, 0.10, 0.15] ,\n",
        " \"max_depth\"        : range(3,10,2),\n",
        " \"min_child_weight\" : range(1,6,2),\n",
        " \"gamma\"            : [ 0.0, 0.1, 0.2 ],\n",
        " \"colsample_bytree\" : [ 0.3, 0.4] \n",
        " }\n",
        "\n",
        "# passing data for hyper parameter tunning with Randomized search cv\n",
        "random_Search(XGBRegressor(), X_train, y_train, XGB_para_grid)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcpHPuRdCaL7"
      },
      "source": [
        "## Using the best parameters and training the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JIL6FaZCnDA"
      },
      "source": [
        "### Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "b5MeVTRnCgqr",
        "outputId": "f35b4c35-0510-4621-f614-79db67c05fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 29.523096985933968\n",
            "RMSE-Test: 29.375518082571176\n",
            "Score-Train: 0.41397423440224734\n",
            "Score-Test: 0.4185712173231173\n",
            "Median_AE-Train: 20.145896003437898\n",
            "Median_AE-Test: 20.019732753262957\n",
            "MeanAE-Train: 20.145896003437898\n",
            "MeanAE-Test: 20.019732753262957 \n",
            "\n",
            "CPU times: total: 1.25 s\n",
            "Wall time: 1.35 s\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGoCAYAAABL+58oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAo0ElEQVR4nO3de5ikdXnn//cHRkUBIRycOHgYRSYmQUUZUQmaxhDWMx4wGEUlZEXMGqOjZhN13VF/Rje4k2C8/CFhBTXqeEQnoEKitCByRo6KgyuoiCcgDRkQheHeP+oZLdruoXqmu6v62+/XddXVTz2H73PfVcPMh+/zVFeqCkmSpJZsM+wCJEmSZpsBR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSU1Lcm2Sg0agjvEk/3XYdUiLxZJhFyBJLUsSIMOuQ1psnMGRtCgkOSLJ2Un+IclEku8m2b9b/4MkP03y8r79T0pyXJJ/S/KfSb6a5KF92/dPckGSm7uf+/dtG0/yziRnA7cBHwGeDLwvyYYk7+v2O7Y79y1JLkry5L4xVif5ZJIPd+e/MsnKvu0PTvLZJD9LcuOmMbttRyb5VpL/SHJaf93SYmHAkbSYPAG4DNgV+BiwFng88AjgcHoBZIe+/V8CvAPYDbgE+ChAkl2AU4H3dmOtAU5NsmvfsS8FjgJ2BI4AzgJeXVU7VNWru30uAPYBdunq+VSS7frGeE5X487AOmBTMNoWOAX4HrAc2KPbjyTPBd4EPB/YvTvvx2f2MkkLnwFH0mJyTVWdWFUbgU8ADwbeXlW/qKrTgV/SCzubnFpVZ1bVL4A3A09K8mDgmcDVVfWRqrqzqj4OXAU8u+/Yk6rqym77HVMVU1X/UlU3dvv8b+A+wO/07fK1qvpCV+9HgMd06/cDlgFvrKpbq+r2qvpat+2VwLuq6ltVdSfwd8A+zuJosTHgSFpMftK3/HOAqpq8rn8G5webFqpqA3ATvWCxjN7sSb/v0ZtJ+Y1jp5Pk9d2lpJuTTAA70Zst2uTHfcu3AdslWUIvmH2vCzCTPRQ4trsMN9HVnEm1Sc0z4EjS9B68aaG7dLULcH33mDwj8hDgh33Pa9L2uz3v7rf578CfAL9VVTsDNzPYDck/AB7ShZ2ptr2yqnbue9y3qr4+wLhSMww4kjS9ZyQ5IMm96d2Lc15V/QD4ArAiyYuTLElyGPB79O6Lmc5PgIf3Pd8RuBP4GbAkyVuB+w9Y1/nAj4B3J9k+yXZJ/qDbdhzwt0l+HyDJTkleOOC4UjMMOJI0vY8B/5PeZZ596d10TFXdCDwLeD1wI/DXwLOq6obNjHUscGj3yab3AqcBXwTW07u8dTsDXNbqzr+R3v0+jwC+D1wHHNZtOxn4X8DaJLcAVwBPH7xlqQ2pmjyLKklKchJwXVW9Zdi1SJo5Z3AkSVJzDDiSJKk5XqKSJEnNcQZHkiQ1xy/b1K/stttutXz58lkb79Zbb2X77beftfGGrbV+oL2eWusH2uvJfkbfQuvpoosuuqGqdp+83oCjX1m+fDkXXnjhrI03Pj7O2NjYrI03bK31A+311Fo/0F5P9jP6FlpPSSb/VnHAS1SSJKlBBhxJktQcA44kSWqOAUeSJM2LNWvWsGbNmnk5lzcZS5KkebF+/fp5O5czOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgDPHknx9M9vGkpwyxfrzklyS5PtJftYtX5Jk+ZwWK0lSI5YMu4DWVdX+W3DMEwCSHAGsrKpXz3ZdkiS1zBmcOZZkQ3qOSXJFksuTHNa3y/2TnJzkm0mOS/Ib70mSbZJcnWT3vuffSbJbkpO6485Ksj7Js7p9tu3OeUGSy5K8cp5aliRp6Aw48+P5wD7AY4CDgGOSPLDbth/weuBRwJ7dvndTVXcB/wK8pFt1EHBpVd3QPV8O/CHwTOC4JNsBfw7cXFWPBx4PvCLJw2a9M0mSRpCXqObHAcDHq2oj8JMkX6UXOm4Bzq+q7wIk+Xi376enGOODwOeBfwSOBE7s2/bJLgRdneS7wCOBg4FHJzm022cnYC/gmv5BkxwFHAWwdOlSxsfHt7rZTTZs2DCr4w1ba/1Aez211g+015P9jL657GliYgJgXl4zA878yGa21T08762s+kGSnyR5KvAEfj2bM90YAf6yqk7bXGFVdTxwPMDKlStrbGxsc7vPyPj4OLM53rC11g+011Nr/UB7PdnP6JvLntauXQswL6+Zl6jmx5nAYd19MbsDTwHO77btl+Rh3b03hwFf28w4J9C7VPXJbjZokxd29+XsCTwc+DZwGvCqJPcCSLIiyfaz25YkSaPJGZy5V8DJwJOAS7vnf11VP07ySOAc4N307sE5s9t3OuvoXZo6cdL6bwNfBZYCR1fV7UlOoHdvzsVJAvwMeO4s9SRJ0kgz4MyhJLsCN1VVAW/sHr9SVePA+HTHV9VJwEl9qx5D7+biqybtenZVvW7SsXcBb+oekiQtKgacOZJkGb3w8p5ZGu9vgFdx93tvJEnSFAw4c6SqrgdWzOJ476Z3KWvy+iNm6xySJLXCm4wlSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElSc5YMuwBJkrQ4rFixYt7OZcCRJEnzYtWqVfN2Li9RSZKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkzYs1a9awZs2aYZchaZHwqxokzYv169cPuwRJi4gzOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgDNJktVJfpjkkr7HznN8zi/M9TkkSVpMlgy7gGFJsm1VbZxm8z9U1XvmoYYAqapnzPW5JElaTBbEDE6SdyT5q77n70zymiRvTHJBksuSvK1v++eSXJTkyiRH9a3fkOTtSc4DnpTk3Um+2R2/2UCTZFWSD3bLj0pyRZL7dTM+H0nylSRXJ3lF3zG/UV+S5Um+leT9wMXAg5Ncm2S3bvvhSc7vZo4+kGTbvtrfmeTSJOcmWdqtX5rk5G79pUn239w4kiQtBqmqYddwj5IsBz5bVY9Lsg1wNfAm4I+AVwIB1gF/X1VnJtmlqm5Kcl/gAuAPq+rGJAUcVlWfTLILcA7wyKqqJDtX1USS1cArgJ91p/+PqjqwO+848A/Am4G/qqqzu/2fBzwR2B74BvAEYG/g0Mn1Ad8HvgvsX1Xndv1dC6wEdu/2eX5V3dGFoHOr6sNd7c+pqn9N8vfALVX1/yX5BHBOVf1jF2J2AJZNN84Ur+1RwFEAS5cu3Xft2rVb+C79pg0bNrDDDjvM2njD1lo/ML89HXfccQAcffTRc3YO36PRZz+jb6H1dOCBB15UVSsnr18Ql6iq6tokNyZ5LLCUXoh4PHBwtwy9f9j3As4EXpPked36B3frbwQ2Ap/p1t8C3A6ckORU4JS+U/7GJaqquivJEcBlwAeq6uy+zZ+vqp8DP09yBrAfcMA09X0f+N6mcDPJHwH7Ahf0rl5xX+Cn3bZf9tV4EfDH3fJTgZd1NW4Ebk7y0s2MczdVdTxwPMDKlStrbGxsqt22yPj4OLM53rC11g/Mb0+bwvNcns/3aPTZz+hrpacFEXA6JwBHAL8NfJBeGHhXVX2gf6ckY8BBwJOq6rYk48B23ebbN913U1V3JtmvG+dFwKvphYXN2QvYQG+GpN/kabCiN2szVX3LgVunGT/Ah6rqb6fYdkf9erptI5t/7zY3jiRJzVsQ9+B0TgaeRm/m5rTucWSSHQCS7JHkAcBO9C4r3ZbkkfQuHf2G7ridquoLwGuBfTZ38iQ7AccCTwF2TXJo3+ZDkmyXZFdgjN5lsenq25wvA4du2i/JLkkeOsAxr+r23zbJ/bdwHEmSmrFgZnCq6pfd5Z+Jbhbm9CS/C5zTXYbZABwOfAk4OsllwLeBqS4FAewIfD7JdvRmPF7Xt+11SQ7ve/5c4K3A+6tqfZI/B85Icma3/XzgVOAhwDuq6nrg+mnqm+6TW1TVN5O8pettG+AO4L8B39vMS/NXwPFdTRuBV1XVOVswjiRJzVgwAaf7h/qJwAs3rauqY+nNqkz29KnGqKod+pZ/RO9emcn7rAZWT3H4kX37/AB4RFcXwPqqOmryAZupb+9J+y3vW/4E8Il7qP3TwKe75Z8Ah0yx/5TjSJK0GCyIS1RJfg/4DvDlqrp62PVIkqTRtiBmcKrqm8DDh13HVLoZH0mSNEIWxAyOJEnSTBhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc1ZMuwCJC0OK1asGHYJkhYRA46kebFq1aphlyBpEfESlSRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHc2LNmjWsW7du2GVIkhYpv6pBc2L9+vVMTEwMuwxJ0iLlDI4kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeAMSZLVSd4w7DokSWqRAWcBS7LtsGuQJGkUGXDmUZI3J/l2kn8Hfqdbt2eSLyW5KMlZSR7Zt/7cJBckeXuSDd36sSRnJPkYcHmSbZMc0+13WZJX9p3vjX3r3zaMniVJGoYlwy5gsUiyL/Ai4LH0XveLgYuA44Gjq+rqJE8A3g88FTgWOLaqPp7k6EnD7QfsXVXXJDkKuLmqHp/kPsDZSU4H9uoe+wEB1iV5SlWdOamuo4CjAJYuXcr4+Pis9DsxMcHGjRtnbbxRsGHDhqb6gfZ6aq0faK8n+xl9rfRkwJk/TwZOrqrbAJKsA7YD9gc+lWTTfvfpfj4JeG63/DHgPX1jnV9V13TLBwOPTnJo93wnesHm4O7xjW79Dt36uwWcqjqeXshi5cqVNTY2tjU9/sratWuZmJhgtsYbBePj4031A+311Fo/0F5P9jP6WunJgDO/atLzbYCJqtpnhuPc2rcc4C+r6rT+HZL8F+BdVfWBGVcpSdIC5z048+dM4HlJ7ptkR+DZwG3ANUleCJCex3T7nwu8oFt+0WbGPQ14VZJ7dWOsSLJ9t/7IJDt06/dI8oBZ70qSpBFkwJknVXUx8AngEuAzwFndppcAf57kUuBK4JBu/WuBVUnOBx4I3DzN0CcA3wQuTnIF8AFgSVWdTu/S1jlJLgc+Dew4y21JkjSSvEQ1j6rqncA7p9j0tCnW/RB4YlVVkhcBF3ZjjAPjfWPeBbype0w+37H0blaWJGlRMeCMrn2B96V39/EEcORwy5EkaeEw4IyoqjoLeMw97ihJkn6D9+BIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0Z6Bf9JfkDYDXw0O6YAFVVD5+70iRJkrbMoL/J+P8ArwMuAjbOXTmSJElbb9CAc3NVfXFOK5EkSZolgwacM5IcA3wW+MWmlVV18ZxUJUmStBUGDThP6H6u7FtXwFNntxxJkqStN1DAqaoD57oQSZKk2TLop6h2Bl4GLO8/pqpeMydVSZIkbYVBL1F9ATgXuBy4a+7KkSRJ2nqDBpztqmrVnFYiSZI0Swb9TcYfSfKKJA9Mssumx5xWpgVtxYoVLFu2bNhlSJIWqUFncH4JHAO8md6np+h++puMNaVVq1YxPj4+7DIkSYvUoAFnFfCIqrphLouRJEmaDYNeoroSuG0uC5EkSZotg87gbAQuSXIGd/9Nxn5MXJIkjZxBA87nuockSdLIG/Q3GX9orguRJEmaLYP+JuNr+PWnp36lqvwUlSRJGjmDXqLq/5LN7YAXAv4eHEmSNJIG+hRVVd3Y9/hhVf0jfpO4JEkaUYNeonpc39Nt6M3o7DgnFUmSJG2lQS9R/e++5TuBa4E/mfVq1Iw1a9Zw3XXXMTY2NuxSJEmL0KCfojpwrgtRW9avX8/ExMSwy5AkLVKbDThJNvsN4lW1ZnbLkSRJ2nr3NIPjfTaSJGnB2WzAqaq3zVchkiRJs2Wgj4kneVCSk5P8NMlPknwmyYPmujhJkqQtMei3iZ8IrAOWAXsA/9qtkyRJGjmDBpzdq+rEqrqze5wE7D6HdUmSJG2xQQPODUkOT7Jt9zgcuHEuC5MkSdpSgwacI+n9Yr8fAz8CDgX+bK6KkiRJ2hqD/ibjdwAvr6r/AEiyC/AeesFHkiRppAw6g/PoTeEGoKpuAh47NyVJkiRtnUEDzjZJfmvTk24GZ9DZH0mSpHk1ky/b/HqSTwNF736cd85ZVZIkSVth0C/b/HCSC4GnAgGeX1XfnNPKJEmSttDAl5m6QGOokSRJI2/Qe3AkSZIWDAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHBmWZKvz3D/sSSnbOG5XpvkfltyrCRJLTPgzLKq2n8eT/daYMqAk2TbeaxDkqSRYsCZZUk2dD/Hkown+XSSq5J8NEm6bU/r1n0NeH7fsauTvKHv+RVJlifZPsmpSS7t1h2W5DXAMuCMJGdsOneStyc5D3hLkpP7xvrjJJ+dn1dBkqTh8gsz59Zjgd8HrgfOBv6g+8qLf6b3tRffAT4xwDhPA66vqmcCJNmpqm5Osgo4sKpu6PbbHriiqt7ahalvJdm9qn4G/Blw4uSBkxwFHAWwdOlSxsfHt7zbPhMTE2zcuHHWxhsFGzZsaKofaK+n1vqB9nqyn9HXSk8GnLl1flVdB5DkEmA5sAG4pqqu7tb/C13A2IzLgfck+V/AKVV11jT7bQQ+A1BVleQjwOFJTgSeBLxs8gFVdTxwPMDKlStrbGxsJv1Na+3atUxMTDBb442C8fHxpvqB9npqrR9oryf7GX2t9OQlqrn1i77ljfw6UNY0+9/J3d+T7QCqaj2wL72g864kb53m+NuramPf8xOBw4E/BT5VVXfOrHxJkhYmA878uwp4WJI9u+d/2rftWuBxAEkeBzysW14G3FZV/wK8Z9M+wH8CO053oqq6nt7lsbcAJ81aB5IkjTgvUc2zqrq9u+/l1CQ3AF8D9u42fwZ4WXc56wJgfbf+UcAxSe4C7gBe1a0/Hvhikh9V1YHTnPKjwO7dt8FLkrQoGHBmWVXt0P0cB8b71r+6b/lLwCOnOPbnwMFTDHstcNoU+/8T8E+Tzz3JAfRuapYkadEw4DQsyUXArcDrh12LJEnzyYDTsKrad9g1SJI0DN5kLEmSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgKM5sWLFCpYtWzbsMiRJi9SSYRegNq1atYrx8fFhlyFJWqScwZEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgaE6sWbOGdevWDbsMSdIi5Vc1aE6sX7+eiYmJYZchSVqknMGRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQacBSzJyiTvHXYdkiSNmiXDLkBbrqouBC4cdP8kS6rqzjksSZKkkeAMzpAlWZ7kqiQnJLkiyUeTHJTk7CRXJ9mve3w9yTe6n7/THTuW5JRueZckn0tyWZJzkzy6W786yfFJTgc+PMRWJUmaN87gjIZHAC8EjgIuAF4MHAA8B3gT8DLgKVV1Z5KDgL8DXjBpjLcB36iq5yZ5Kr0ws0+3bV/ggKr6+eQTJzmqOy9Lly5lfHx8VhqamJhg48aNszbeKNiwYUNT/UB7PbXWD7TXk/2MvlZ6MuCMhmuq6nKAJFcCX66qSnI5sBzYCfhQkr2AAu41xRgH0IWeqvpKkl2T7NRtWzdVuOn2PR44HmDlypU1NjY2Kw2tXbuWiYkJZmu8UTA+Pt5UP9BeT631A+31ZD+jr5WevEQ1Gn7Rt3xX3/O76IXQdwBnVNXewLOB7aYYI1Osq+7nrbNUpyRJC4IBZ2HYCfhht3zENPucCbwEevfmADdU1S1zXZgkSaPIgLMw/D3wriRnA9tO2rZplmY1sDLJZcC7gZfPX3mSJI0W78EZsqq6Fti77/kR02xb0XfY/+h+7grc1O17E3DIFOOvnsVyJUlaEAw4C1SS5wDvBI4cdi2SJI0aA84CVVXrgHXDrkOSpFHkPTiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4mhMrVqxg2bJlwy5DkrRILRl2AWrTqlWrGB8fH3YZkqRFyhkcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUdzYs2aNaxbt27YZUiSFim/i0pzYv369UxMTAy7DEnSIuUMjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHkiQ1x4AjSZKaY8CRJEnNMeBIkqTmGHAkSVJzDDiSJKk5BhxJktQcA44kSWqOAUeSJDXHgCNJkpoz1ICT5DlJ/qZbXp3kDVswxliSm5Nc0j3+fQ7qHE/y/STpW/e5JBvu4bidk/zFbNczzbk2dD+XJfn0fJxTkqRRNdSAU1XrqurdszDUWVW1T/c4qH9DkiWzMD7ABPAH3Zg7Aw8c4JidgSkDTpJtZ6muu6mq66vq0LkYW5KkhWLOAk6S5UmuSnJCkiuSfDTJQUnOTnJ1kv2SHJHkfVMcu2eSLyW5KMlZSR7ZrX9hN9alSc7czLmPSPKpJP8KnJ5kl27G5bIk5yZ5dLff6iQfSnJ6kmuTPD/J3ye5vDv/vfqGXQu8qFt+PvDZSed8Y5ILunO8rVv9bmDPbmbpmG626YwkHwMuT7JdkhO7830jyYF99X++q+HbSf5n33lWda/BFUleO83rfkW3/PtJzu/Of1mSve7hbZMkqQmzNbsxnUcALwSOAi4AXgwcADwHeBPwuWmOOx44uqquTvIE4P3AU4G3Av+lqn7YzaJs8uQkl3TLnwJ+CDwJeHRV3ZTkn4BvVNVzkzwV+DCwT7f/nsCBwO8B5wAvqKq/TnIy8My+Gr8M/HM38/Kirqf/AZDkYGAvYD8gwLokTwH+Bti7qvbp9hvr9tm7qq5J8nqAqnpUF+JOT7KiO99+wN7AbcAFSU4FCvgz4Andec5L8tWq+sY0r+PRwLFV9dEk9wbmZNZIkqRRM9cB55qquhwgyZXAl6uqklwOLJ/qgCQ7APsDn+q75eU+3c+zgZOSfJK7z6CcVVXP6hvjCODfquqmbtUBwAsAquorSXZNslO37YtVdUdX07bAl7r1k2vcCHwNOAy4b1Vd21ffwd1jU9DYgV7g+f4ULZ5fVdf01fVPXV1XJfkesCng/FtV3dj189lu3wJOrqpb+9Y/ue+8k50DvDnJg4DPVtXVk3dIchS9sMbSpUsZHx+fZqiZmZiYYOPGjbM23ijYsGFDU/1Aez211g+015P9jL5WeprrgPOLvuW7+p7ftZlzbwNMbJr16FdVR3czOs8ELknyG/v0ubVvOVNsr/4aq+quJHdU1ab1U9W4FjgZWD1pfYB3VdUH7rYyWb4FdU2ur//55vb/zQGqPpbkPHqv12lJ/mtVfWXSPsfTmzFj5cqVNTY2NpNTTGvt2rVMTEwwW+ONgvHx8ab6gfZ6aq0faK8n+xl9rfQ0ch8Tr6pbgGuSvBAgPY/plvesqvOq6q3ADcCDBxz2TOAl3RhjwA3deWbqLOBdwMcnrT8NOLKbfSLJHkkeAPwnsOOAda0AHgJ8u9v2x929Q/cFnktv9upM4LlJ7pdke+B5XU1TSvJw4LtV9V5gHfDoGfQqSdKCNdczOFvqJcD/n+QtwL3ozZxcChzT3SgbevfEXAr84QDjrQZOTHIZvXtaXr4lRXWzO++ZYv3pSX4XOKe7bLUBOLyq/m93U/UVwBeBUycd+n7guO7y2J3AEVX1i26MrwEfoXcf08eq6kKAJCcB53fHn7CZ+2+gdznt8CR3AD8G3r4FbUuStODMWcCpqmvp3SS76fkR02w7qVu3um/7NcDTphjz+VOcarx79O930qZxu+c3AYdMMd7qSc93mGpbVY1Ncd7J+x8LHDvFPi+eot5N224HjphqbOCnVfXqKcZbA6yZrpb+17aq3kVvxkmSpEVl5C5RSZIkba1RvUS1qE2egZIkSTPjDI4kSWqOAUeSJDXHgCNJkppjwJEkSc0x4EiSpOYYcCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkSRJzTHgSJKk5hhwJElScww4kiSpOQYcSZLUHAOOJElqjgFHc2LFihUsW7Zs2GVIkhapJcMuQG1atWoV4+Pjwy5DkrRIOYMjSZKaY8CRJEnNMeBIkqTmGHAkSVJzUlXDrkEjIsnPgO/N4pC7ATfM4njD1lo/0F5PrfUD7fVkP6NvofX00KraffJKA47mTJILq2rlsOuYLa31A+311Fo/0F5P9jP6WunJS1SSJKk5BhxJktQcA47m0vHDLmCWtdYPtNdTa/1Aez3Zz+hroifvwZEkSc1xBkeSJDXHgCNJkppjwNFWSfK0JN9O8p0kfzPF9iR5b7f9siSPG0adMzFAT49Mck6SXyR5wzBqnIkB+nlJ995cluTrSR4zjDpnYoCeDun6uSTJhUkOGEadg7qnfvr2e3ySjUkOnc/6tsQA79FYkpu79+iSJG8dRp2DGuQ96nq6JMmVSb463zXOxADvzxv73psruj93uwyj1i1WVT58bNED2Bb4v8DDgXsDlwK/N2mfZwBfBAI8EThv2HXPQk8PAB4PvBN4w7BrnoV+9gd+q1t+eiPv0Q78+h7DRwNXDbvuremnb7+vAF8ADh123bPwHo0Bpwy71lnsZ2fgm8BDuucPGHbdW9PPpP2fDXxl2HXP9OEMjrbGfsB3quq7VfVLYC1wyKR9DgE+XD3nAjsneeB8FzoD99hTVf20qi4A7hhGgTM0SD9fr6r/6J6eCzxonmucqUF62lDd38zA9sAof5pikP+OAP4S+Azw0/ksbgsN2tNCMUg/LwY+W1Xfh97fE/Nc40zM9P35U+Dj81LZLDLgaGvsAfyg7/l13bqZ7jNKFlq992Sm/fw5vRm3UTZQT0mel+Qq4FTgyHmqbUvcYz9J9gCeBxw3j3VtjUH/3D0pyaVJvpjk9+entC0ySD8rgN9KMp7koiQvm7fqZm7gvxeS3A94Gr1wvaAsGXYBWtAyxbrJ/6c8yD6jZKHVe08G7ifJgfQCzkjfr8KAPVXVycDJSZ4CvAM4aK4L20KD9POPwH+vqo3JVLuPnEF6upjedwhtSPIM4HPAXnNd2BYapJ8lwL7AHwH3Bc5Jcm5VrZ/r4rbATP6eezZwdlXdNIf1zAkDjrbGdcCD+54/CLh+C/YZJQut3nsyUD9JHg2cADy9qm6cp9q21Izeo6o6M8meSXarqlH8AsFB+lkJrO3CzW7AM5LcWVWfm5cKZ+4ee6qqW/qWv5Dk/Qv8PboOuKGqbgVuTXIm8BhgFAPOTP4behEL8PIUeIlKW+cCYK8kD0tyb3r/IaybtM864GXdp6meCNxcVT+a70JnYJCeFpJ77CfJQ4DPAi8d0f/bnGyQnh6RLg10n9y7NzCqwe0e+6mqh1XV8qpaDnwa+IsRDjcw2Hv0233v0X70/j1asO8R8HngyUmWdJd1ngB8a57rHNRAf88l2Qn4Q3q9LTjO4GiLVdWdSV4NnEbvrvwPVtWVSY7uth9H7xMfzwC+A9wG/Nmw6h3EID0l+W3gQuD+wF1JXkvvEwi3TDfusAz4Hr0V2BV4f/fvzZ01wt8kPGBPL6AXrO8Afg4c1nfT8UgZsJ8FZcCeDgVeleROeu/Rixbye1RV30ryJeAy4C7ghKq6YnhVT28Gf+aeB5zezUotOH5VgyRJao6XqCRJUnMMOJIkqTkGHEmS1BwDjiRJao4BR5IkNceAI0mSmmPAkbQgJHlNkm8l+egMj1ue5MVzVVffeb6QZOe5Pk/f+XZO8hfzdT5pofH34EhaELovznx6VV0zw+PGgDdU1bNmeNy2VbVxJsfMlyTb0vtV+6dU1d7DrkcaRc7gSBp5SY4DHg6sS/LmJB9MckGSbyQ5pNtneZKzklzcPfbvDn83vV+hf0mS1yU5Isn7+sY+pQtBJNmQ5O1JzqP3TdeHJzm/O/YDXbCYrsZrk+zW1XFVkhOSXJHko0kOSnJ2kqu7ryUgyeokH0nylW79K7r1SXJMd+zlSQ7r1o8lOSPJx4DLu7727Go7JskOSb7c9X75pNflW0n+OcmVSU5Pct9u2yOS/Ht63+h9cZI9u/Vv7F7fy5K8bbbeR2leVZUPHz58jPwDuJbeF03+HXB4t25nel9muD1wP2C7bv1ewIXd8hi9mY5N4xwBvK/v+SnAWLdcwJ90y78L/Ctwr+75+4GXDVDfcuBO4FH0/ifyIuCD9L7B+RDgc93+q4FL6X3z9G7AD4Bl9L5m4t/o/Qr9pcD3gQd2fdwKPKw7fjlwRd/5lwD375Z3o/f1KOmrZ59u2yf7Xr/zgOd1y9t1r+HBwPHdsdt0r89Thv3++/Ax04ffRSVpoTkYeE6SN3TPtwMeQu/bkN+XZB9gI7BiC8beCHymW/4jYF/ggu47uu4L/HTAca6pqssBklwJfLmqKsnl9ALHJp+vqp8DP09yBrAfcADw8epdHvtJkq8CjwduAc6v6S/RBfi7JE+h911Ie9ALSJvquaRbvghYnmRHYI+qOhmgqm7v6j2Y3mv8jW7/HegFxjMH7F0aCQYcSQtNgBdU1bfvtjJZDfwEeAy9mYfbpzn+Tu5+eX67vuXb69f33QT4UFX97RbU+Iu+5bv6nt/F3f/enXwTZHXnnc7mvvTwJcDuwL5VdUeSa/l1b/31bKQX1qY7T4B3VdUHNnMuaeR5D46kheY04C/TTaskeWy3fifgR1V1F/BSepd4AP4T2LHv+GuBfZJsk+TB9GZNpvJl4NAkD+jOs0uSh85qJ3BIku2S7ErvEtQF9GZKDkuybZLdgacA509x7OS+dgJ+2oWbA4HN1lpVtwDXJXkuQJL7JLkfvdf3yCQ7dOv32PQaSAuJAUfSQvMO4F7AZUmu6J5D7x6Zlyc5l97lqU2zHZcBd3Y30r4OOBu4ht6Nuu8BLp7qJFX1TeAtwOlJLqN3X8wDZ7mX84FTgXOBd1TV9cDJXc2XAl8B/rqqfjxFfTcCZ3c3Ix8DfBRYmeRCerM5Vw1w/pcCr+n6+zrw21V1OvAx4JzuktqnuXuQkhYEPyYuSUPQXVLbUFXvGXYtUoucwZEkSc1xBkeSZqD7HTn3mbT6pZs+NSVpNBhwJElSc7xEJUmSmmPAkSRJzTHgSJKk5hhwJElSc/4fP+uDXNC/RoMAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a Random Forest Regressor model to the train dataset\n",
        "\n",
        "# Instantiate the model\n",
        "rf= RandomForestRegressor(**{'n_estimators': 64, 'min_samples_leaf': 0.1, 'max_features': 'auto', 'max_depth': 27.0, 'bootstrap': False})\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model to the data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(rf)\n",
        "\n",
        "\n",
        "# visualizing the inportance of features.\n",
        "fig, ax = visualize_importance(rf.feature_importances_,train_X)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-5qOWsUDJwz"
      },
      "source": [
        "### Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "gehdG2AFCguX",
        "outputId": "d60393bc-d2f3-4282-b56e-5284e7c9c521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 18.8543602600951\n",
            "RMSE-Test: 19.031634623892458\n",
            "Score-Train: 0.7609897717097625\n",
            "Score-Test: 0.7559506585176115\n",
            "Median_AE-Train: 13.261989126776157\n",
            "Median_AE-Test: 13.521433387391752\n",
            "MeanAE-Train: 13.261989126776157\n",
            "MeanAE-Test: 13.521433387391752 \n",
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'columns'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[1;32m<timed exec>:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\nikhi\\salary_prediction\\data_analysis\\Employee_attrition_withoutcode.ipynb Cell 191\u001b[0m line \u001b[0;36mvisualize_importance\u001b[1;34m(feature_importances, feat_train_df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y356sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m _df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y356sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m _df[\u001b[39m'\u001b[39m\u001b[39mfeature_importance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feature_importances\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y356sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m _df[\u001b[39m'\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feat_train_df\u001b[39m.\u001b[39;49mcolumns\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y356sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m feature_importance_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([feature_importance_df,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y356sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m _df], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y356sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# grouping all data and sorting in descending order\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Import GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Fit a Gradient Boosting Regressor model to the train dataset\n",
        "\n",
        "# Instantiate the model\n",
        "GBR = GradientBoostingRegressor(**{'n_estimators': 64, 'min_samples_split': 0.1, 'max_depth': 8.0, 'learning_rate': 0.25})\n",
        "GBR.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(GBR)\n",
        "\n",
        "\n",
        "# visualizing the inportance of features.\n",
        "fig, ax = visualize_importance(GBR.feature_importances_, X_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8__MVjVDb9b"
      },
      "source": [
        "### Decision Tree Regrsessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJk0bTSbCgyw",
        "outputId": "05425f9d-76ed-4251-fe20-5636892c870a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 33.97080887408061\n",
            "RMSE-Test: 34.218410797718384\n",
            "Score-Train: 0.22410195016040502\n",
            "Score-Test: 0.2110579050947401\n",
            "Median_AE-Train: 23.367941936277532\n",
            "Median_AE-Test: 23.632058063722468\n",
            "MeanAE-Train: 23.367941936277532\n",
            "MeanAE-Test: 23.632058063722468 \n",
            "\n",
            "CPU times: total: 0 ns\n",
            "Wall time: 19 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a Decision Tree Regressor model to the train dataset\n",
        "\n",
        "# Instantiate the model\n",
        "DTR = DecisionTreeRegressor(**{'splitter': 'random', 'min_weight_fraction_leaf': 0.2, 'min_samples_leaf': 0.2, 'max_features': None, 'max_depth': 20.0})\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "DTR.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(DTR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0POlWMhaDuOI"
      },
      "source": [
        "### XGBoost Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "fu39YChlCg2i",
        "outputId": "6d09130e-2d56-453e-a32a-6fd724622874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE-Train: 18.8667292200314\n",
            "RMSE-Test: 18.97657390610936\n",
            "Score-Train: 0.7606760747605443\n",
            "Score-Test: 0.7573607416781303\n",
            "Median_AE-Train: 13.267845153808594\n",
            "Median_AE-Test: 13.476028442382812\n",
            "MeanAE-Train: 13.267845153808594\n",
            "MeanAE-Test: 13.476028442382812 \n",
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'columns'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[1;32m<timed exec>:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\nikhi\\salary_prediction\\data_analysis\\Employee_attrition_withoutcode.ipynb Cell 195\u001b[0m line \u001b[0;36mvisualize_importance\u001b[1;34m(feature_importances, feat_train_df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y363sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m _df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y363sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m _df[\u001b[39m'\u001b[39m\u001b[39mfeature_importance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feature_importances\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y363sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m _df[\u001b[39m'\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feat_train_df\u001b[39m.\u001b[39;49mcolumns\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y363sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m feature_importance_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([feature_importance_df,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y363sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m _df], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikhi/salary_prediction/data_analysis/Employee_attrition_withoutcode.ipynb#Y363sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# grouping all data and sorting in descending order\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Fit a XGB Regressor model to the train dataset\n",
        "\n",
        "# Instantiate the model\n",
        "xgbr = XGBRegressor(**{'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.15, 'gamma': 0.1, 'colsample_bytree': 0.4})\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model to the data\n",
        "xgbr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# print score of the model\n",
        "print_score(xgbr)\n",
        "\n",
        "\n",
        "# visualizing the inportance of features.\n",
        "fig, ax = visualize_importance(xgbr.feature_importances_, X_train)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn6M12bKD9M_"
      },
      "source": [
        "## Comparing the metrics for tuned models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY_Ep3AfCg69"
      },
      "outputs": [],
      "source": [
        "models= [DTR, rf,GBR, xgbr]\n",
        "names = ['Dtree', 'Forest','GBR', 'Xboost']\n",
        "comp_model_train,comp_model_test = compare_models(models=models, names=names, X_train=X_train, X_test=X_test,y_test=y_test,y_train=y_train)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "ZnVtcECIEA64",
        "outputId": "00f5d879-aaad-4b80-df4a-ee2746ca7c49"
      },
      "outputs": [],
      "source": [
        "print(\"Metrics on train data\")\n",
        "comp_model_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq2sHiagseCE"
      },
      "source": [
        "### Now working with the test dataset provided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "f65ChY0dseCE",
        "outputId": "934dfae4-eb4a-4516-959d-a43e7f16d49e"
      },
      "outputs": [],
      "source": [
        "# test data \n",
        "test_X = test_data\n",
        "test_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIfspmcMseCF"
      },
      "outputs": [],
      "source": [
        "# passing test data for scaling\n",
        "col_test = ['yearsExperience','milesFromMetropolis']\n",
        "test_X = scale_data(test_X, col_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "YRMSny8VoI0Q",
        "outputId": "783137f0-831a-4087-ab4a-5a7561a7206f"
      },
      "outputs": [],
      "source": [
        "# passing test dataset for one hot encoding process\n",
        "encoder = OneHotEncoder()\n",
        "test_drop = test_X.drop(['jobType','degree','major','industry'], axis=1)\n",
        "test_X = encoder.fit_transform(test_X.drop(col_test, axis=1))\n",
        "\n",
        "test_X = test_X.join(test_drop['yearsExperience'])\n",
        "test_X = test_X.join(test_drop['milesFromMetropolis'])\n",
        "test_X.head()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_V4f8L7seCF",
        "outputId": "17621c7a-ddb5-474b-ea87-48bad325d726"
      },
      "outputs": [],
      "source": [
        "# Perforn the prediction on the test dataset\n",
        "y_predicted = GBR.predict(test_X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqpO2zrAseCF"
      },
      "outputs": [],
      "source": [
        "# creating a dataframe of predicted results \n",
        "predictions = pd.DataFrame(y_predicted)\n",
        "predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "P4r8hIneseCF",
        "outputId": "4f48d9af-0205-4330-c242-68214b78e8b7"
      },
      "outputs": [],
      "source": [
        "# predicted values in dataframe\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc9yyP3RsL7y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUIOkO3fJz2c"
      },
      "source": [
        "**Business Problem:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iI1S9UZqWshi",
        "outputId": "ddfdea30-8399-4871-e356-c60bfe00433e"
      },
      "outputs": [],
      "source": [
        "### we take same samples provided my the manager so that we can explain him the difference between the salary the person should be getting as the salary the person\n",
        "sample = train_data.sample(100)\n",
        "sample\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample.iloc[:,0:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbJD7i7UNlCh"
      },
      "outputs": [],
      "source": [
        "train_cat = sample.iloc[:,0:4]   #categorical variables for sample\n",
        "\n",
        "#encodind the samples\n",
        "encoder = OneHotEncoder()\n",
        "train_X = encoder.fit_transform(train_cat)\n",
        "\n",
        "#processing the sample data\n",
        "train = train_X.join(sample.iloc[:,4:])\n",
        "\n",
        "#taking those samples whose salary is very less i.e the reason for employee resigning\n",
        "sample = train[train['salary'] < 60]\n",
        "sample\n",
        "\n",
        "\n",
        "\n",
        "#Preparing the x and y values\n",
        "x_sample = sample.drop('salary', axis=1)\n",
        "y_sample = sample['salary']\n",
        "\n",
        "\n",
        "\n",
        "# passing test data for scaling\n",
        "col_test = ['yearsExperience','milesFromMetropolis']\n",
        "sample_x = scale_data(x_sample, col_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46t9BMdGmveQ",
        "outputId": "48cd1598-e7b7-4a6e-d6be-1d0d7a8f0ff4"
      },
      "outputs": [],
      "source": [
        "#predicting the sample\n",
        "predicted_out = GBR.predict(sample_x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDMiRkXDmbcR",
        "outputId": "4525f5c8-c039-4480-a5cb-901724b100c6"
      },
      "outputs": [],
      "source": [
        "y_sample  #Real values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCURK4f9Ojpe"
      },
      "source": [
        "### As we can see the difference in values.\n",
        "\n",
        "**Example**: The last sample the real value is 58 but the model predicted it to be 74...This may be because the other competitors are offering him more as compared to the current salary..so he is leaving the company."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRlIt0YGDb5e"
      },
      "source": [
        "**Here, we can clearly see a difference between the real salary given to the employee and the predicted salary which may be the probable reason for the employee to leave the company**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8U-KYk-Ue3l"
      },
      "source": [
        "## **`Insights`**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsD729CoR5IJ"
      },
      "source": [
        "- ### Mr.Francis provides these following insignts to Mr. Andrew after working on the dataset provided:\n",
        "\n",
        "**1.Major employee of your company are not happy with the salary they are being provided..even if they have the required skills to do the job as compared to other competitors.**\n",
        "\n",
        "**2.The employee living in the metro cities are satisfied with the salaries they are receiving...but employee's living far from the city are not getting a satisfactory salary which is the most probable reason for them leaving the company.**\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uIUUsjfR5IJ"
      },
      "source": [
        "## **`solution`**:\n",
        "\n",
        "1. Either increase the salary of these employee's(if they have the required degree and major)\n",
        "\n",
        "2. Provide accomodation to people living in places far from city so that they are satisfied.\n",
        "\n",
        "3. provide appraisal or some token of appreciation to such employee's\n",
        "\n",
        "Note: take all the necessary steps to make the employee more loyal to the company"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoFwv9nzR5IK"
      },
      "source": [
        "## **`QUESTION`**:\n",
        "\n",
        "**Mr. Pandey provides the detail of a new hired employee and asks us to predict a range of salary which the company can offer to that employee:**\n",
        "\n",
        "**job_type** = CTO\n",
        "\n",
        "**degree** = Masters\n",
        "\n",
        "**major** = Biology\n",
        "\n",
        "**industry** = Health\n",
        "\n",
        "**experience** = 17\n",
        "\n",
        "miles from **metropolis** = 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "213f22dcR5IK"
      },
      "source": [
        "## **`SOLUTION`**:\n",
        "\n",
        "We will fit in these data points into the model and suppose the model provide us the answer as 180\n",
        "\n",
        "In this case we will basically provide the Manager with a range of salaries i.e\n",
        "\n",
        "We can offer him a salary range of 175-190 dollars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EhEeUOWilkY"
      },
      "source": [
        "## **`CONCLUSION`**:\n",
        "According to this model, the predicted value we got,\n",
        "matches with the actual target values. Does the model is performing well.\n",
        "Even though we use only 50000 samples, the model may perform much better when trained on complete dataset.\n",
        "We have performed EDA, preprocessing, buid different models, visualized feature importance, did hyper parameter tunning of each model and did prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqACX1s5ilg1"
      },
      "source": [
        "## Congratulation for completing the assignment.\n",
        "You have learned a lot while doing this assignment."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "f5ARlvYSoIz9",
        "f7HPmp72oIz_",
        "ZXkVodrHeQ8C"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
